{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOp2SDzSbIxTOGML9h23Q9P"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 02) 정상/감염 이진분류 모델 학습(Inception v4)"
      ],
      "metadata": {
        "id": "z1juJZgh_8Z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_background = 1\n",
        "use_agumentation = 1\n",
        "use_dropout = 1\n",
        "use_l2 = 1"
      ],
      "metadata": {
        "id": "70f-qo0wj-Gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라이브러리 설치 및 Import"
      ],
      "metadata": {
        "id": "j2f4Vu4gAM42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' 패키지 설치 '''\n",
        "!pip install torch torchvision\n",
        "\n",
        "# =============================\n",
        "# torch : 모델 실행, 학습, 추론에 필수적인 PyTorch 프레임워크\n",
        "# torchvision : 이미지 처리 관련 도구 제공\n",
        "# ============================="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3JaYUpQAP6e",
        "outputId": "eecde818-bbdb-407f-894c-1e92010d627e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Google Drive 연동'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "'''필수 라이브러리 import'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import zipfile\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwU4aNSCAR5Y",
        "outputId": "004efa80-df96-4fc3-cfd1-df1a82a40ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 불러오기"
      ],
      "metadata": {
        "id": "pWHCwWFEAltP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Label 데이터 불러오기'''\n",
        "rawdata = pd.read_csv(\"/content/drive/MyDrive/data/rawdata.csv\")"
      ],
      "metadata": {
        "id": "HAzCnRGJApPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Image 데이터 불러오기'''\n",
        "if use_background:\n",
        "  zipName = 'data'\n",
        "else:\n",
        "  zipName = 'raw'\n",
        "\n",
        "# data 폴더 생성\n",
        "targetPath = '/content/data/'\n",
        "os.makedirs(targetPath, exist_ok=True)\n",
        "\n",
        "# 압축 파일 content로 복사 => content에 있으면 처리속도가 비교적 빠름\n",
        "rootZip = f'/content/drive/MyDrive/data/{zipName}.zip'\n",
        "targetZip = f'/content/{zipName}.zip'\n",
        "shutil.copyfile(rootZip, targetZip)\n",
        "\n",
        "# zipfile.ZipFile로 압축 파일을 열고, 압축된 모든 파일을 targetPath로 이동(압축 해제)\n",
        "with zipfile.ZipFile(targetZip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(targetPath)"
      ],
      "metadata": {
        "id": "-I56jW4lAsiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 Split"
      ],
      "metadata": {
        "id": "H0AfAUzFAt3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Train:Val:Test = 6:2:2 분할'''\n",
        "# rawdata를 분할. train:(val+test) = 6:4\n",
        "train, temp = train_test_split(rawdata, test_size=0.4, random_state=1)\n",
        "\n",
        "# rawdata를 분할. val:test = 5:5\n",
        "val, test = train_test_split(temp, test_size=0.5, random_state=1)"
      ],
      "metadata": {
        "id": "OmEJwNX7BAqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋 클래스, Transform 생성"
      ],
      "metadata": {
        "id": "Wss5QZOvD17G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' DataSet 클래스 정의 '''\n",
        "# =============================\n",
        "# 목적 : DataFrame에 저장된 이미지 경로와 라벨 등을 불러오고, 전처리 후 (image, label) 리턴\n",
        "# 매개변수(?)\n",
        "#  - dataframe : 이미지 파일 이름/클래스 등이 포함된 변수\n",
        "#  - rootDir : 이미지들이 저장된 경로\n",
        "#  - transform : torchvision.transforms를 사용한 이미지 전처리 파이프라인(전처리 묶음? 정도로 이해하면 될 듯)\n",
        "# =============================\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, dataframe, rootDir, transform=None):\n",
        "    self.dataframe = dataframe\n",
        "    self.rootDir = rootDir\n",
        "    self.transform = transform\n",
        "\n",
        "  # 데이터셋의 총 샘플 수 반환\n",
        "  def __len__(self):\n",
        "    return len(self.dataframe)\n",
        "\n",
        "  # idx번째 데이터 리턴\n",
        "  def __getitem__(self, idx):\n",
        "    # DataFrame의 idx번째 행을 row에 저장\n",
        "    row = self.dataframe.iloc[idx]\n",
        "    # 이미지 경로 불러오기(row['image']는 파일명이므로, 상위 경로와 더해줌; 파일 이름이 '.JPG'로 된 경우도 있어서 통일)\n",
        "    imgName = os.path.join(self.rootDir, row['image'].replace('.JPG', '.jpg'))\n",
        "\n",
        "    # 이미지 파일을 열고, RGB로 변환\n",
        "    image = Image.open(imgName).convert('RGB')\n",
        "\n",
        "    # trasform이 정의되어 있다면, 전처리 적용\n",
        "    if self.transform:\n",
        "        image = self.transform(image)\n",
        "\n",
        "    # 라벨 저장\n",
        "    label = row['class']\n",
        "\n",
        "    # (전처리된 이미지, 라벨) 리턴\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "VC_MaxdUD70V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Transform 정의'''\n",
        "# train, val, test 용도에 따라 전처리를 다르게 적용\n",
        "if use_agumentation:\n",
        "  transform = {\n",
        "      'train': transforms.Compose([\n",
        "          # 이미지를 299x299로 통일 (Inception v4 입력 크기)\n",
        "          transforms.Resize((299, 299), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "          # 확률적으로 이미지를 좌우 반전 (데이터 증강)\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          # -15 ~ +15도 사이로 랜덤 회전 (데이터 증강)\n",
        "          transforms.RandomRotation(15),\n",
        "          # 밝기, 대비, 채도 랜덤 조절 (데이터 증강)\n",
        "          transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "          # 10 % 비율로 좌우 또는 상화 랜덤 이동 (데이터 증강)\n",
        "          transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "          # PIL 이미지를 Tensor 형식으로 변환 (0~299 >> 0~1 실수형)\n",
        "          transforms.ToTensor(),\n",
        "          # 평균 및 표준편차를 기준으로 정규화 (Image Net으로 사전 학습도니 모델과 일치시키기 위해)\n",
        "          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "      ]),\n",
        "      'val': transforms.Compose([\n",
        "          # 이미지를 299x299로 통일 (Inception v4 입력 크기)\n",
        "          transforms.Resize((299, 299), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "          # PIL 이미지를 Tensor 형식으로 변환 (0~299 >> 0~1 실수형)\n",
        "          transforms.ToTensor(),\n",
        "          # 평균 및 표준편차를 기준으로 정규화 (Image Net으로사전 학습도니 모델과 일치시키기 위해)\n",
        "          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "      ]),\n",
        "      'test': transforms.Compose([ # val과 동일/ train과 달리 평가 용도기 때문에 val과 test에는 데이터 증강이 없음.\n",
        "          transforms.Resize((299, 299), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "      ])\n",
        "  }\n",
        "else:\n",
        "  transform = {\n",
        "      'train': transforms.Compose([\n",
        "          # 이미지를 299x299로 통일 (Inception v4 입력 크기)\n",
        "          transforms.Resize((299, 299), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "          # PIL 이미지를 Tensor 형식으로 변환 (0~299 >> 0~1 실수형)\n",
        "          transforms.ToTensor(),\n",
        "          # 평균 및 표준편차를 기준으로 정규화 (Image Net으로 사전 학습도니 모델과 일치시키기 위해)\n",
        "          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "      ]),\n",
        "      'val': transforms.Compose([\n",
        "          # 이미지를 299x299로 통일 (Inception v4 입력 크기)\n",
        "          transforms.Resize((299, 299), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "          # PIL 이미지를 Tensor 형식으로 변환 (0~299 >> 0~1 실수형)\n",
        "          transforms.ToTensor(),\n",
        "          # 평균 및 표준편차를 기준으로 정규화 (Image Net으로사전 학습도니 모델과 일치시키기 위해)\n",
        "          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "      ]),\n",
        "      'test': transforms.Compose([ # val과 동일/ train과 달리 평가 용도기 때문에 val과 test에는 데이터 증강이 없음.\n",
        "          transforms.Resize((299, 299), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "      ])\n",
        "  }"
      ],
      "metadata": {
        "id": "CK15qzZgCqQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset 불러오기\n",
        "trainDataset = CustomDataset(train, '/content/data', transform=transform['train'])\n",
        "valDataset = CustomDataset(val, '/content/data', transform=transform['val'])\n",
        "testDataset = CustomDataset(test, '/content/data', transform=transform['test'])\n",
        "\n",
        "# DataLoader 불러오기\n",
        "trainLoader = DataLoader(trainDataset, batch_size=32, shuffle=False)\n",
        "valLoader = DataLoader(valDataset, batch_size=32, shuffle=False)\n",
        "testLoader = DataLoader(testDataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "463sGLomlNym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습, 테스트 메소드 정의"
      ],
      "metadata": {
        "id": "P1VaSpJ4EMW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Inception-V4 모델 생성 및 정의 '''\n",
        "\n",
        "# 사용할 디바이스 설정 : GPU(cuda)가 가능하면 GPU, 아니면 CPU 사용\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# =============================\n",
        "# 목적 : 모델을 불러오고 재정의\n",
        "# =============================\n",
        "def create_model():\n",
        "    # 학습목적으로 Inception v4모델을 직접 만들거임\n",
        "    # 타 모델과 차이점: 여러 크기의 필터를 병렬로 사용함 -> 다양한 관점?에서 특징 추출 가능함\n",
        "\n",
        "    # 구조: Input -> STEM -> Inception-A -> Reduction-A -> I-B -> R-B -> I-C -> Global Average Pooling -> Dropout -> FC -> Softmax\n",
        "\n",
        "    # Stem: 모델의 첫 부분으로, Input을 받아 특징 추출 및 차원 축소 역할\n",
        "    # Inception: 다양한 필터를 병렬로 사용해 특징 추출. 뒷 문자가 커질수록 고수준의 특징 추출(복잡한 패턴)\n",
        "    # Reduction: 이미지 해상도 줄임(다운샘플링). 다음 블록을 위한 연결 다리 역할\n",
        "    # Global Average Pooling: 마지막 전체 특징을 압축해 1차원 벡터로 만듬\n",
        "    # Dropout: 과적합 방지\n",
        "    # FC: 최종 분류 출력\n",
        "\n",
        "    # Stem의 출력은 항상 35x35임.\n",
        "    class Stem(nn.Module):\n",
        "      def __init__(self):\n",
        "          super(Stem, self).__init__()\n",
        "          self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2)  # 149x149\n",
        "          self.conv2 = nn.Conv2d(32, 32, kernel_size=3)           # 147x147\n",
        "          self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 147x147\n",
        "\n",
        "          self.branch1 = nn.MaxPool2d(kernel_size=3, stride=2)    # 73x73\n",
        "          self.branch2 = nn.Conv2d(64, 96, kernel_size=3, stride=2)  # 73x73\n",
        "\n",
        "          self.branch3a = nn.Sequential(\n",
        "              nn.Conv2d(160, 64, kernel_size=1),\n",
        "              nn.Conv2d(64, 96, kernel_size=3)\n",
        "          )\n",
        "\n",
        "          self.branch3b = nn.Sequential(\n",
        "              nn.Conv2d(160, 64, kernel_size=1),\n",
        "              nn.Conv2d(64, 64, kernel_size=(7, 1), padding=(3, 0)),\n",
        "              nn.Conv2d(64, 64, kernel_size=(1, 7), padding=(0, 3)),\n",
        "              nn.Conv2d(64, 96, kernel_size=3)\n",
        "          )\n",
        "\n",
        "          self.branch4a = nn.Conv2d(192, 192, kernel_size=3, stride=2)\n",
        "          self.branch4b = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "      def forward(self, x):\n",
        "          x = self.conv1(x)\n",
        "          x = self.conv2(x)\n",
        "          x = self.conv3(x)\n",
        "          x1 = self.branch1(x)\n",
        "          x2 = self.branch2(x)\n",
        "          x = torch.cat([x1, x2], 1)\n",
        "\n",
        "          x1 = self.branch3a(x)\n",
        "          x2 = self.branch3b(x)\n",
        "          x = torch.cat([x1, x2], 1)\n",
        "\n",
        "          x1 = self.branch4a(x)\n",
        "          x2 = self.branch4b(x)\n",
        "          x = torch.cat([x1, x2], 1)\n",
        "          return x\n",
        "\n",
        "\n",
        "    # InceptionA의 출력 채널 수는 항상 384임.\n",
        "    class InceptionA(nn.Module):\n",
        "      def __init__(self, in_channels):\n",
        "        super(InceptionA, self).__init__()\n",
        "\n",
        "        # 1x1 Conv\n",
        "        self.branch1 = nn.Conv2d(in_channels, 96, kernel_size=1)\n",
        "\n",
        "        # 1x1 Conv -> 3x3 Conv\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=1),\n",
        "            nn.Conv2d(64, 96, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        # 1x1 Conv -> 3x3 Conv -> 3x3 Conv\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=1),\n",
        "            nn.Conv2d(64, 96, kernel_size=3, padding=1),\n",
        "            nn.Conv2d(96, 96, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        # Average Pooling -> 1x1 Conv\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_channels, 96, kernel_size=1)\n",
        "        )\n",
        "      def forward(self, x):\n",
        "        b1 = self.branch1(x)\n",
        "        b2 = self.branch2(x)\n",
        "        b3 = self.branch3(x)\n",
        "        b4 = self.branch4(x)\n",
        "        # 채널 방향으로 합치기\n",
        "        out = torch.cat([b1, b2, b3, b4], dim=1)\n",
        "        return out\n",
        "\n",
        "    class ReductionA(nn.Module):\n",
        "      def __init__(self, in_channels):\n",
        "        super(ReductionA, self).__init__()\n",
        "\n",
        "        self.branch1 = nn.Conv2d(in_channels, 384, kernel_size=3, stride=2)\n",
        "\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 192, kernel_size=1),\n",
        "            nn.Conv2d(192, 224, kernel_size=3, padding=1),\n",
        "            nn.Conv2d(224, 256, kernel_size=3, stride=2)\n",
        "        )\n",
        "\n",
        "        self.branch3 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "      def forward(self, x):\n",
        "        b1 = self.branch1(x)\n",
        "        b2 = self.branch2(x)\n",
        "        b3 = self.branch3(x)\n",
        "        out = torch.cat([b1, b2, b3], dim=1)\n",
        "        return out\n",
        "\n",
        "    class InceptionB(nn.Module):\n",
        "      def __init__(self, in_channels):\n",
        "        super(InceptionB, self).__init__()\n",
        "\n",
        "        self.branch1 = nn.Conv2d(in_channels, 384, kernel_size=1)\n",
        "\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 192, kernel_size=1),\n",
        "            nn.Conv2d(192, 224, kernel_size=(1, 7), padding=(0, 3)),\n",
        "            nn.Conv2d(224, 256, kernel_size=(7, 1), padding=(3, 0))\n",
        "        )\n",
        "\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 192, kernel_size=1),\n",
        "            nn.Conv2d(192, 192, kernel_size=(7, 1), padding=(3, 0)),\n",
        "            nn.Conv2d(192, 224, kernel_size=(1, 7), padding=(0, 3)),\n",
        "            nn.Conv2d(224, 224, kernel_size=(7, 1), padding=(3, 0)),\n",
        "            nn.Conv2d(224, 256, kernel_size=(1, 7), padding=(0, 3))\n",
        "        )\n",
        "\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_channels, 128, kernel_size=1)\n",
        "        )\n",
        "\n",
        "      def forward(self, x):\n",
        "        b1 = self.branch1(x)\n",
        "        b2 = self.branch2(x)\n",
        "        b3 = self.branch3(x)\n",
        "        b4 = self.branch4(x)\n",
        "        out = torch.cat([b1, b2, b3, b4], dim=1)\n",
        "        return out\n",
        "\n",
        "    class ReductionB(nn.Module):\n",
        "      def __init__(self, in_channels):\n",
        "        super(ReductionB, self).__init__()\n",
        "\n",
        "        self.branch1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 192, kernel_size=1),\n",
        "            nn.Conv2d(192, 192, kernel_size=3, stride=2)\n",
        "        )\n",
        "\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 256, kernel_size=1),\n",
        "            nn.Conv2d(256, 256, kernel_size=(1, 7), padding=(0, 3)),\n",
        "            nn.Conv2d(256, 320, kernel_size=(7, 1), padding=(3, 0)),\n",
        "            nn.Conv2d(320, 320, kernel_size=3, stride=2)\n",
        "        )\n",
        "\n",
        "        self.branch3 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "      def forward(self, x):\n",
        "        b1 = self.branch1(x)\n",
        "        b2 = self.branch2(x)\n",
        "        b3 = self.branch3(x)\n",
        "        out = torch.cat([b1, b2, b3], dim=1)\n",
        "        return out\n",
        "\n",
        "    class InceptionC(nn.Module):\n",
        "      def __init__(self, in_channels):\n",
        "        super(InceptionC, self).__init__()\n",
        "\n",
        "        self.branch1 = nn.Conv2d(in_channels, 256, kernel_size=1)\n",
        "\n",
        "        self.branch2_1 = nn.Conv2d(in_channels, 384, kernel_size=1)\n",
        "        self.branch2_2 = nn.Conv2d(384, 256, kernel_size=(1, 3), padding=(0, 1))\n",
        "        self.branch2_3 = nn.Conv2d(384, 256, kernel_size=(3, 1), padding=(1, 0))\n",
        "\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 384, kernel_size=1),\n",
        "            nn.Conv2d(384, 448, kernel_size=3, padding=1),\n",
        "            nn.Conv2d(448, 512, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        self.branch3_2a = nn.Conv2d(512, 256, kernel_size=(1, 3), padding=(0, 1))\n",
        "        self.branch3_2b = nn.Conv2d(512, 256, kernel_size=(3, 1), padding=(1, 0))\n",
        "\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_channels, 256, kernel_size=1)\n",
        "        )\n",
        "\n",
        "      def forward(self, x):\n",
        "        b1 = self.branch1(x)\n",
        "\n",
        "        b2 = self.branch2_1(x)\n",
        "        b2a = self.branch2_2(b2)\n",
        "        b2b = self.branch2_3(b2)\n",
        "        b2 = torch.cat([b2a, b2b], dim=1)\n",
        "\n",
        "        b3 = self.branch3(x)\n",
        "        b3a = self.branch3_2a(b3)\n",
        "        b3b = self.branch3_2b(b3)\n",
        "        b3 = torch.cat([b3a, b3b], dim=1)\n",
        "\n",
        "        b4 = self.branch4(x)\n",
        "\n",
        "        out = torch.cat([b1, b2, b3, b4], dim=1)\n",
        "        return out\n",
        "\n",
        "    class InceptionV4(nn.Module):\n",
        "      def __init__(self, num_classes=2):\n",
        "        super(InceptionV4, self).__init__()\n",
        "\n",
        "        self.stem = Stem()\n",
        "\n",
        "        self.InceptionA = nn.Sequential(\n",
        "            InceptionA(384),\n",
        "            InceptionA(384),\n",
        "            InceptionA(384),\n",
        "            InceptionA(384)\n",
        "        )\n",
        "\n",
        "        self.reductionA = ReductionA(384)\n",
        "\n",
        "        self.InceptionB = nn.Sequential(\n",
        "            InceptionB(1024),\n",
        "            InceptionB(1024),\n",
        "            InceptionB(1024),\n",
        "            InceptionB(1024),\n",
        "            InceptionB(1024),\n",
        "            InceptionB(1024),\n",
        "            InceptionB(1024),\n",
        "        )\n",
        "\n",
        "        self.reductionB = ReductionB(1024)\n",
        "\n",
        "        self.InceptionC = nn.Sequential(\n",
        "            InceptionC(1536),\n",
        "            InceptionC(1536),\n",
        "            InceptionC(1536)\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        if use_dropout:\n",
        "          self.head_drop = nn.Dropout(p=0.2)\n",
        "          self.classif = nn.Sequential(\n",
        "              nn.Linear(1536, 256),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(0.2),\n",
        "              nn.Linear(256, num_classes),\n",
        "          )\n",
        "        else:\n",
        "          self.head_drop = nn.Dropout(p=0.0)\n",
        "          self.classif = nn.Sequential(\n",
        "              nn.Linear(1536, 256),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(256, num_classes),\n",
        "          )\n",
        "\n",
        "      def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.InceptionA(x)\n",
        "        x = self.reductionA(x)\n",
        "        x = self.InceptionB(x)\n",
        "        x = self.reductionB(x)\n",
        "        x = self.InceptionC(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.head_drop(x)\n",
        "        x = self.classif(x)\n",
        "        return x\n",
        "\n",
        "    return InceptionV4().to(device)\n",
        "\n",
        "# 모델 저장 시에는 다음처럼 state_dict만 저장하세요:\n",
        "# torch.save(model.state_dict(), path)\n",
        "\n",
        "# 모델 로딩 시에는 다음처럼 사용하세요:\n",
        "# model = create_model()\n",
        "# model.load_state_dict(torch.load(path))\n",
        "# model.eval()\n"
      ],
      "metadata": {
        "id": "C3zC1ZxPo_QH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 학습 모델 '''\n",
        "# =============================\n",
        "# 목적 : 모델 학습\n",
        "# Early Stopping : val loss가 5번 이상 개선이 안될 경우, 종료\n",
        "# =============================\n",
        "def TrainModel(model, criterion, optimizer, scheduler, trainLoader, valLoader, numEpochs=20, patience=5):\n",
        "    # Early Stopping 관련 변수\n",
        "    # loss 기준값을 최댓값으로 설정\n",
        "    best_val_loss = float('inf')\n",
        "    # early stopping counter 0으로 설정\n",
        "    counter = 0\n",
        "    # best model 저장 경로 설정\n",
        "    best_model_path = f\"/content/drive/MyDrive/model/Inception v4 초기학습/{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model.pth\"\n",
        "\n",
        "    # Backbone 동결 상태에서 fc layer만 학습\n",
        "    for epoch in range(numEpochs):\n",
        "        # Train\n",
        "        # 모델을 학습 모드로 설정\n",
        "        model.train()\n",
        "        runningLoss = 0.0\n",
        "        runningCorrects = 0\n",
        "\n",
        "        # 훈련 데이터 반복 학습\n",
        "        for inputs, labels in trainLoader:\n",
        "            # 이미지와 라벨(클래스)\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # 기존 그래디언트 초기화\n",
        "            optimizer.zero_grad()\n",
        "            # 모델 forward pass\n",
        "            outputs = model(inputs)\n",
        "            # 손실함수 계산 (출력, 정답)\n",
        "            loss = criterion(outputs, labels)\n",
        "            # 역전파 학습\n",
        "            loss.backward()\n",
        "            # 파라미터 업데이트\n",
        "            optimizer.step()\n",
        "\n",
        "            # 예측값 계산\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            # 손실 합산\n",
        "            runningLoss += loss.item() * inputs.size(0)\n",
        "            # 정확도 합산\n",
        "            runningCorrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # 반복 횟수 단위로 Train 평균 손실 및 정확도 계산\n",
        "        epochLoss = runningLoss / len(trainLoader.dataset)\n",
        "        epochAcc = runningCorrects.double() / len(trainLoader.dataset)\n",
        "        print(f\"Epoch {epoch+1}/{numEpochs} - Train Loss: {epochLoss:.4f} Acc: {epochAcc:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        # 모델을 평가 모드로 설정\n",
        "        model.eval()\n",
        "        valLoss = 0.0\n",
        "        valCorrects = 0\n",
        "\n",
        "        # 그래디언트 비활성화\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in valLoader:\n",
        "                # 이미지와 라벨(클래스)\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                # 모델 forward pass\n",
        "                outputs = model(inputs)\n",
        "                # 손실함수 계산 (출력, 정답)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # 예측값 계산\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                # 손실 합산\n",
        "                valLoss += loss.item() * inputs.size(0)\n",
        "                # 정확도 합산\n",
        "                valCorrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # 반복 횟수 단위로 Validation 평균 손실 및 정확도 계산\n",
        "        valLoss /= len(valLoader.dataset)\n",
        "        val_acc = valCorrects.double() / len(valLoader.dataset)\n",
        "        print(f\"Validation Loss: {valLoss:.4f} Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # Scheduler: Validation Loss 기반으로 학습률 조정\n",
        "        scheduler.step(valLoss)\n",
        "\n",
        "        # Early Stopping\n",
        "        # 개선이 되면\n",
        "        if valLoss < best_val_loss:\n",
        "            best_val_loss = valLoss\n",
        "            counter = 0\n",
        "            torch.save(model, best_model_path)\n",
        "            print(f\"Renewal best model: {best_val_loss:.4f}\")\n",
        "        # 개선이 안되면\n",
        "        else:\n",
        "            counter += 1\n",
        "            print(f\"No improvement in {counter}/{patience} epochs\")\n",
        "            if counter >= patience:\n",
        "                break"
      ],
      "metadata": {
        "id": "JEmAA8AGj-IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def TestModel(model, testLoader):\n",
        "    all_preds = []\n",
        "    all_probs = []  # AUC 계산용 softmax 확률\n",
        "    all_labels = []\n",
        "\n",
        "    testCorrects = 0\n",
        "    testLoss = 0.0\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testLoader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # 예측 클래스\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            # softmax 확률 (클래스 1의 확률만)\n",
        "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
        "\n",
        "            testLoss += loss.item() * inputs.size(0)\n",
        "            testCorrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # 평균 계산\n",
        "    testLoss /= len(testLoader.dataset)\n",
        "    testAcc = testCorrects.double() / len(testLoader.dataset)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    precision = precision_score(all_labels, all_preds, average='macro')\n",
        "    recall = recall_score(all_labels, all_preds, average='macro')\n",
        "    auc = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "    print(f\"Test Accuracy  : {testAcc:.4f}\")\n",
        "    print(f\"Test Loss      : {testLoss:.4f}\")\n",
        "    print(f\"ROC-AUC        : {auc:.4f}\")\n",
        "    print(f\"Precision      : {precision:.4f}\")\n",
        "    print(f\"Recall         : {recall:.4f}\")\n",
        "    print(f\"F1-macro       : {f1:.4f}\")\n",
        "\n",
        "    return testAcc.item(), testLoss, auc, precision, recall, f1"
      ],
      "metadata": {
        "id": "NuuvedRxBo8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(model):\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            nn.init.constant_(m.weight, 1)\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            if 'classif' in name:\n",
        "                nn.init.normal_(m.weight, mean=0.0, std=0.5)  # 💥 폭넓게\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0.2)\n",
        "            else:\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0.1)"
      ],
      "metadata": {
        "id": "EVAwlnmwmGiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "x = torch.randn(4, 3, 299, 299).to(device)\n",
        "y = model(x)\n",
        "print(\"FC output shape:\", y.shape)\n",
        "print(\"Logits mean/std:\", y.mean().item(), y.std().item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "858cHaOqBlJS",
        "outputId": "160ec2e0-3f49-4d42-ed63-8ea3f073fa11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FC output shape: torch.Size([4, 2])\n",
            "Logits mean/std: 0.019397489726543427 0.035522330552339554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "def init_weights_he(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.zeros_(m.bias)"
      ],
      "metadata": {
        "id": "x3xJc7uqYCGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습 및 테스트"
      ],
      "metadata": {
        "id": "4rXgBKTrFQo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,2):\n",
        "  # 모델 불러오기\n",
        "  model = create_model()\n",
        "  model.apply(init_weights_he)\n",
        "\n",
        "  # CrossEntropyLoss로 손실 함수 설정\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  # Adam으로 옵티마이저로 사용 (filter를 통해 require_grad = True, 동결되지 않은 것만 업데이트)\n",
        "  # weight_decay = 1e-4 : L2 정규화 적용으로 과적합 방지\n",
        "  if use_l2:\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "  else:\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "  # 학습률 스케줄러 설정\n",
        "  # 검증 손실이 줄어들지 않으면 learning rate 줄임 (수렴 및 안정화)\n",
        "  # min 모드 : 손실이 최소화되지 않으면 작동 / factor : 학습률을 x배 줄임 / patience : x번 학습동안 개선되지 않으면 발동 / verbose : 메시지 출력\n",
        "  scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "  # Train 모델 실행\n",
        "  TrainModel(model, criterion, optimizer, scheduler, trainLoader, valLoader, numEpochs=20, patience=5)\n",
        "\n",
        "  os.rename(f\"/content/drive/MyDrive/model/Inception v4 초기학습/{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model.pth\", f\"/content/drive/MyDrive/model/Inception v4 초기학습/{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model_{i+1}.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "Ko7sT-B2d9KT",
        "outputId": "752cd552-a594-4d4d-e6a1-c02b0fc00fab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - Train Loss: 18758691966393.8828 Acc: 0.5207\n",
            "Validation Loss: 412088465931.9070 Acc: 0.6492\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "Can't pickle local object 'create_model.<locals>.InceptionV4'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-a5e066fd85e0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;31m# Train 모델 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mTrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/content/drive/MyDrive/model/Inception v4 초기학습/{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model.pth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"/content/drive/MyDrive/model/Inception v4 초기학습/{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model_{i+1}.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-89650c90217c>\u001b[0m in \u001b[0;36mTrainModel\u001b[0;34m(model, criterion, optimizer, scheduler, trainLoader, valLoader, numEpochs, patience)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mbest_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Renewal best model: {best_val_loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# 개선이 안되면\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m             _save(\n\u001b[0m\u001b[1;32m    945\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                 \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyTorchPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m     \u001b[0mdata_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'create_model.<locals>.InceptionV4'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model.pth\")\n",
        "for i in range(2):\n",
        "  best_model_path = f\"/content/drive/MyDrive/model/Inception v4 초기학습/{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model_{i+1}.pth\"\n",
        "  model = torch.load(best_model_path, weights_only=False)\n",
        "  model.to(device)\n",
        "\n",
        "  # 테스트\n",
        "  result = TestModel(model, testLoader)\n",
        "  print()"
      ],
      "metadata": {
        "id": "Zov9aTHBePqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "구버전"
      ],
      "metadata": {
        "id": "aTayF3Amo1V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' 학습 모델 '''\n",
        "# =============================\n",
        "# 목적 : 모델 학습\n",
        "# 단일 단계 학습 (Inception v4: 사전학습 X)\n",
        "# Early Stopping : val loss가 6번 이상 개선이 안될 경우, 종료\n",
        "# =============================\n",
        "def TrainModel(model, criterion, optimizer, scheduler, trainLoader, valLoader, numEpochs=12, patience=6):\n",
        "    # Early Stopping 관련 변수\n",
        "    best_val_loss = float('inf')\n",
        "    counter = 0\n",
        "    best_model_path = f\"/content/drive/MyDrive/model/Inception v4 초기학습/{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model.pth\"\n",
        "\n",
        "    for epoch in range(numEpochs):\n",
        "        # Train\n",
        "        model.train()\n",
        "        runningLoss = 0.0\n",
        "        runningCorrects = 0\n",
        "\n",
        "        for inputs, labels in trainLoader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            runningLoss += loss.item() * inputs.size(0)\n",
        "            runningCorrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epochLoss = runningLoss / len(trainLoader.dataset)\n",
        "        epochAcc = runningCorrects.double() / len(trainLoader.dataset)\n",
        "        print(f\"Epoch {epoch+1}/{numEpochs} - Train Loss: {epochLoss:.4f} Acc: {epochAcc:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        valLoss = 0.0\n",
        "        valCorrects = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in valLoader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                valLoss += loss.item() * inputs.size(0)\n",
        "                valCorrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        valLoss /= len(valLoader.dataset)\n",
        "        val_acc = valCorrects.double() / len(valLoader.dataset)\n",
        "        print(f\"Validation Loss: {valLoss:.4f} Acc: {val_acc:.4f}\")\n",
        "\n",
        "        #scheduler.step(valLoss) # 확인 필요\n",
        "        scheduler.step()\n",
        "        if valLoss < best_val_loss:\n",
        "            best_val_loss = valLoss\n",
        "            counter = 0\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            print(f\"Renewal best model: {best_val_loss:.4f}\")\n",
        "        else:\n",
        "            counter += 1\n",
        "            print(f\"No improvement in {counter}/{patience} epochs\")\n",
        "            if counter >= patience:\n",
        "                break"
      ],
      "metadata": {
        "id": "gX4Y44G431vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 불러오기\n",
        "model = create_model()\n",
        "\n",
        "# 가중치 초기화 적용\n",
        "initialize_weights(model)\n",
        "print(type(model.stem.conv1.weight))  # Parameter\n",
        "print(model.stem.conv1.weight.mean(), model.stem.conv1.weight.std())\n",
        "\n",
        "# 손실 함수 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 옵티마이저 설정 (프리징 없음 → 전체 파라미터 사용)\n",
        "if use_l2:\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4) # lr => 0.001?\n",
        "else:\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Cosine Annealing 스케줄러 설정 (warm-up 없이 단일 단계) # 확인 필요 동일한 방식으로 해야하지 않을까...!\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optimizer,\n",
        "    T_max=20,\n",
        "    eta_min=1e-6\n",
        ")\n",
        "\n",
        "# 모델 학습 실행\n",
        "TrainModel(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    trainLoader=trainLoader,\n",
        "    valLoader=valLoader,\n",
        "    numEpochs=20,\n",
        "    patience=5\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHcfTFM9aKQY",
        "outputId": "fa87c58c-cd7f-416a-aba7-cfe9ead84808",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.nn.parameter.Parameter'>\n",
            "tensor(1.6994e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0798, device='cuda:0', grad_fn=<StdBackward0>)\n",
            "Training full model (no freezing, since pretrained weights are not used)\n",
            "Epoch 1/20 - Train Loss: 11.6860 Acc: 0.5956\n",
            "Validation Loss: 0.6984 Acc: 0.6667\n",
            "Saved best model with Val Loss: 0.6984\n",
            "Epoch 2/20 - Train Loss: 0.6851 Acc: 0.6680\n",
            "Validation Loss: 0.7240 Acc: 0.6531\n",
            "No improvement in 1/5 epochs\n",
            "Epoch 3/20 - Train Loss: 0.6393 Acc: 0.6673\n",
            "Validation Loss: 0.6054 Acc: 0.7074\n",
            "Saved best model with Val Loss: 0.6054\n",
            "Epoch 4/20 - Train Loss: 0.6132 Acc: 0.6970\n",
            "Validation Loss: 0.6467 Acc: 0.6938\n",
            "No improvement in 1/5 epochs\n",
            "Epoch 5/20 - Train Loss: 0.5894 Acc: 0.6932\n",
            "Validation Loss: 0.5805 Acc: 0.7267\n",
            "Saved best model with Val Loss: 0.5805\n",
            "Epoch 6/20 - Train Loss: 0.6000 Acc: 0.6990\n",
            "Validation Loss: 0.5881 Acc: 0.7035\n",
            "No improvement in 1/5 epochs\n",
            "Epoch 7/20 - Train Loss: 0.5624 Acc: 0.7151\n",
            "Validation Loss: 0.5844 Acc: 0.7093\n",
            "No improvement in 2/5 epochs\n",
            "Epoch 8/20 - Train Loss: 0.5859 Acc: 0.7164\n",
            "Validation Loss: 0.5905 Acc: 0.7151\n",
            "No improvement in 3/5 epochs\n",
            "Epoch 9/20 - Train Loss: 0.5608 Acc: 0.7235\n",
            "Validation Loss: 0.6014 Acc: 0.7306\n",
            "No improvement in 4/5 epochs\n",
            "Epoch 10/20 - Train Loss: 0.5533 Acc: 0.7293\n",
            "Validation Loss: 0.5205 Acc: 0.7442\n",
            "Saved best model with Val Loss: 0.5205\n",
            "Epoch 11/20 - Train Loss: 0.5248 Acc: 0.7435\n",
            "Validation Loss: 0.4847 Acc: 0.7752\n",
            "Saved best model with Val Loss: 0.4847\n",
            "Epoch 12/20 - Train Loss: 0.5378 Acc: 0.7339\n",
            "Validation Loss: 0.4885 Acc: 0.7694\n",
            "No improvement in 1/5 epochs\n",
            "Epoch 13/20 - Train Loss: 0.5116 Acc: 0.7545\n",
            "Validation Loss: 0.4742 Acc: 0.7771\n",
            "Saved best model with Val Loss: 0.4742\n",
            "Epoch 14/20 - Train Loss: 0.4919 Acc: 0.7513\n",
            "Validation Loss: 0.4574 Acc: 0.7771\n",
            "Saved best model with Val Loss: 0.4574\n",
            "Epoch 15/20 - Train Loss: 0.4763 Acc: 0.7733\n",
            "Validation Loss: 0.4449 Acc: 0.7849\n",
            "Saved best model with Val Loss: 0.4449\n",
            "Epoch 16/20 - Train Loss: 0.4662 Acc: 0.7720\n",
            "Validation Loss: 0.4386 Acc: 0.8004\n",
            "Saved best model with Val Loss: 0.4386\n",
            "Epoch 17/20 - Train Loss: 0.4571 Acc: 0.7875\n",
            "Validation Loss: 0.4357 Acc: 0.7829\n",
            "Saved best model with Val Loss: 0.4357\n",
            "Epoch 18/20 - Train Loss: 0.4450 Acc: 0.7868\n",
            "Validation Loss: 0.4266 Acc: 0.8023\n",
            "Saved best model with Val Loss: 0.4266\n",
            "Epoch 19/20 - Train Loss: 0.4373 Acc: 0.7933\n",
            "Validation Loss: 0.4260 Acc: 0.8101\n",
            "Saved best model with Val Loss: 0.4260\n",
            "Epoch 20/20 - Train Loss: 0.4389 Acc: 0.7972\n",
            "Validation Loss: 0.4172 Acc: 0.8043\n",
            "Saved best model with Val Loss: 0.4172\n",
            "Training completed. Best model saved at: /content/drive/MyDrive/model/11110_best_model_초기학습.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 모델 구조를 다시 정의\n",
        "model = create_model()\n",
        "\n",
        "# 2. 저장된 가중치 로드\n",
        "best_model_path = f\"/content/drive/MyDrive/model/{use_background}{use_agumentation}{use_dropout}{use_freezing}{use_l2}_best_model_초기학습.pth\"\n",
        "state_dict = torch.load(best_model_path)\n",
        "\n",
        "# 3. 모델에 가중치 적용\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "# 4. 디바이스로 이동\n",
        "model.to(device)\n",
        "\n",
        "# 5. 평가 모드 전환 (꼭!)\n",
        "model.eval()\n",
        "\n",
        "# 6. 테스트 실행\n",
        "result = TestModel(model, testLoader)\n"
      ],
      "metadata": {
        "id": "lICt0ucFQJvP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b87c4ee-3871-4bc3-b20c-27636dfd5a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy  : 0.8101\n",
            "Test Loss      : 0.3916\n",
            "ROC-AUC        : 0.9080\n",
            "Precision      : 0.8135\n",
            "Recall         : 0.8109\n",
            "F1-macro       : 0.8098\n"
          ]
        }
      ]
    }
  ]
}