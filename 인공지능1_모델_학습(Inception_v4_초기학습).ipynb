{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPnRnqxUMxqwxnGbDio9/FN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bisil2/AI1_Final_Project/blob/main/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A51_%EB%AA%A8%EB%8D%B8_%ED%95%99%EC%8A%B5(Inception_v4_%EC%B4%88%EA%B8%B0%ED%95%99%EC%8A%B5).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_background = 1\n",
        "use_agumentation = 1\n",
        "use_dropout = 1\n",
        "use_l2 = 0"
      ],
      "metadata": {
        "id": "70f-qo0wj-Gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라이브러리 설치 및 Import"
      ],
      "metadata": {
        "id": "j2f4Vu4gAM42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' 패키지 설치 '''\n",
        "!pip install torch torchvision\n",
        "\n",
        "# =============================\n",
        "# torch : 모델 실행, 학습, 추론에 필수적인 PyTorch 프레임워크\n",
        "# torchvision : 이미지 처리 관련 도구 제공\n",
        "# ============================="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3JaYUpQAP6e",
        "outputId": "4e3ecabf-f00c-414e-db8f-fbe7d281a064",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Google Drive 연동'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "'''필수 라이브러리 import'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import zipfile\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "from torchsummary import summary\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwU4aNSCAR5Y",
        "outputId": "734710fe-8ad1-4f04-9795-afa2bbe1fd14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 불러오기"
      ],
      "metadata": {
        "id": "pWHCwWFEAltP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Label 데이터 불러오기'''\n",
        "rawdata = pd.read_csv(\"/content/drive/MyDrive/data/rawdata.csv\")"
      ],
      "metadata": {
        "id": "HAzCnRGJApPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Image 데이터 불러오기'''\n",
        "if use_background:\n",
        "  zipName = 'data'\n",
        "else:\n",
        "  zipName = 'raw'\n",
        "\n",
        "# data 폴더 생성\n",
        "targetPath = '/content/data/'\n",
        "os.makedirs(targetPath, exist_ok=True)\n",
        "\n",
        "# 압축 파일 content로 복사 => content에 있으면 처리속도가 비교적 빠름\n",
        "rootZip = f'/content/drive/MyDrive/data/{zipName}.zip'\n",
        "targetZip = f'/content/{zipName}.zip'\n",
        "shutil.copyfile(rootZip, targetZip)\n",
        "\n",
        "# zipfile.ZipFile로 압축 파일을 열고, 압축된 모든 파일을 targetPath로 이동(압축 해제)\n",
        "with zipfile.ZipFile(targetZip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(targetPath)"
      ],
      "metadata": {
        "id": "-I56jW4lAsiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 Split"
      ],
      "metadata": {
        "id": "H0AfAUzFAt3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Train:Val:Test = 6:2:2 분할'''\n",
        "# rawdata를 분할. train:(val+test) = 6:4\n",
        "train, temp = train_test_split(rawdata, test_size=0.4, random_state=1)\n",
        "\n",
        "# rawdata를 분할. val:test = 5:5\n",
        "val, test = train_test_split(temp, test_size=0.5, random_state=1)"
      ],
      "metadata": {
        "id": "OmEJwNX7BAqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋 클래스, Transform 생성"
      ],
      "metadata": {
        "id": "Wss5QZOvD17G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' DataSet 클래스 정의 '''\n",
        "# =============================\n",
        "# 목적 : DataFrame에 저장된 이미지 경로와 라벨 등을 불러오고, 전처리 후 (image, label) 리턴\n",
        "# 매개변수(?)\n",
        "#  - dataframe : 이미지 파일 이름/클래스 등이 포함된 변수\n",
        "#  - rootDir : 이미지들이 저장된 경로\n",
        "#  - transform : torchvision.transforms를 사용한 이미지 전처리 파이프라인(전처리 묶음? 정도로 이해하면 될 듯)\n",
        "# =============================\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, dataframe, rootDir, transform=None):\n",
        "    self.dataframe = dataframe\n",
        "    self.rootDir = rootDir\n",
        "    self.transform = transform\n",
        "\n",
        "  # 데이터셋의 총 샘플 수 반환\n",
        "  def __len__(self):\n",
        "    return len(self.dataframe)\n",
        "\n",
        "  # idx번째 데이터 리턴\n",
        "  def __getitem__(self, idx):\n",
        "    # DataFrame의 idx번째 행을 row에 저장\n",
        "    row = self.dataframe.iloc[idx]\n",
        "    # 이미지 경로 불러오기(row['image']는 파일명이므로, 상위 경로와 더해줌; 파일 이름이 '.JPG'로 된 경우도 있어서 통일)\n",
        "    imgName = os.path.join(self.rootDir, row['image'].replace('.JPG', '.jpg'))\n",
        "\n",
        "    # 이미지 파일을 열고, RGB로 변환\n",
        "    image = Image.open(imgName).convert('RGB')\n",
        "\n",
        "    # trasform이 정의되어 있다면, 전처리 적용\n",
        "    if self.transform:\n",
        "        image = self.transform(image)\n",
        "\n",
        "    # 라벨 저장\n",
        "    label = row['class']\n",
        "\n",
        "    # (전처리된 이미지, 라벨) 리턴\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "VC_MaxdUD70V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Transform 정의'''\n",
        "# train, val, test 용도에 따라 전처리를 다르게 적용\n",
        "if use_agumentation:\n",
        "  transform = {\n",
        "      'train': transforms.Compose([\n",
        "          # 이미지를 299x299로 통일 (Inception v4 입력 크기)\n",
        "          transforms.Resize((299, 299)),\n",
        "          # 확률적으로 이미지를 좌우 반전 (데이터 증강)\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          # -15 ~ +15도 사이로 랜덤 회전 (데이터 증강)\n",
        "          transforms.RandomRotation(15),\n",
        "          # 밝기, 대비, 채도 랜덤 조절 (데이터 증강)\n",
        "          transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "          # 10 % 비율로 좌우 또는 상화 랜덤 이동 (데이터 증강)\n",
        "          transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "          # PIL 이미지를 Tensor 형식으로 변환 (0~299 >> 0~1 실수형)\n",
        "          transforms.ToTensor(),\n",
        "          # 평균 및 표준편차를 기준으로 정규화 (Image Net으로 사전 학습도니 모델과 일치시키기 위해)\n",
        "          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "      ]),\n",
        "      'val': transforms.Compose([\n",
        "          # 이미지를 299x299로 통일 (Inception v4 입력 크기)\n",
        "          transforms.Resize((299, 299)),\n",
        "          # PIL 이미지를 Tensor 형식으로 변환 (0~299 >> 0~1 실수형)\n",
        "          transforms.ToTensor(),\n",
        "          # 평균 및 표준편차를 기준으로 정규화 (Image Net으로사전 학습도니 모델과 일치시키기 위해)\n",
        "          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "      ]),\n",
        "      'test': transforms.Compose([ # val과 동일/ train과 달리 평가 용도기 때문에 val과 test에는 데이터 증강이 없음.\n",
        "          transforms.Resize((299, 299)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "      ])\n",
        "  }\n",
        "else:\n",
        "  transform = {\n",
        "      'train': transforms.Compose([\n",
        "          # 이미지를 299x299로 통일 (Inception v4 입력 크기)\n",
        "          transforms.Resize((299, 299)),\n",
        "          # PIL 이미지를 Tensor 형식으로 변환 (0~299 >> 0~1 실수형)\n",
        "          transforms.ToTensor(),\n",
        "          # 평균 및 표준편차를 기준으로 정규화 (Image Net으로 사전 학습도니 모델과 일치시키기 위해)\n",
        "          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "      ]),\n",
        "      'val': transforms.Compose([\n",
        "          # 이미지를 299x299로 통일 (Inception v4 입력 크기)\n",
        "          transforms.Resize((299, 299)),\n",
        "          # PIL 이미지를 Tensor 형식으로 변환 (0~299 >> 0~1 실수형)\n",
        "          transforms.ToTensor(),\n",
        "          # 평균 및 표준편차를 기준으로 정규화 (Image Net으로사전 학습도니 모델과 일치시키기 위해)\n",
        "          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "      ]),\n",
        "      'test': transforms.Compose([ # val과 동일/ train과 달리 평가 용도기 때문에 val과 test에는 데이터 증강이 없음.\n",
        "          transforms.Resize((299, 299)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "      ])\n",
        "  }"
      ],
      "metadata": {
        "id": "CK15qzZgCqQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset 불러오기\n",
        "trainDataset = CustomDataset(train, '/content/data', transform=transform['train'])\n",
        "valDataset = CustomDataset(val, '/content/data', transform=transform['val'])\n",
        "testDataset = CustomDataset(test, '/content/data', transform=transform['test'])\n",
        "\n",
        "# DataLoader 불러오기\n",
        "trainLoader = DataLoader(trainDataset, batch_size=32, shuffle=False)\n",
        "valLoader = DataLoader(valDataset, batch_size=32, shuffle=False)\n",
        "testLoader = DataLoader(testDataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "463sGLomlNym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습, 테스트 메소드 정의"
      ],
      "metadata": {
        "id": "P1VaSpJ4EMW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' 학습 모델 '''\n",
        "# =============================\n",
        "# 목적 : 모델 학습\n",
        "# Early Stopping : val loss가 5번 이상 개선이 안될 경우, 종료\n",
        "# =============================\n",
        "def TrainModel(model, criterion, optimizer, scheduler, trainLoader, valLoader, numEpochs=20, patience=5):\n",
        "    # Early Stopping 관련 변수\n",
        "    # loss 기준값을 최댓값으로 설정\n",
        "    best_val_loss = float('inf')\n",
        "    # early stopping counter 0으로 설정\n",
        "    counter = 0\n",
        "    # best model 저장 경로 설정\n",
        "    best_model_path = f\"/content/drive/MyDrive/model/Inception v4 초기학습/{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model.pth\"\n",
        "\n",
        "    # Backbone 동결 상태에서 fc layer만 학습\n",
        "    for epoch in range(numEpochs):\n",
        "        # Train\n",
        "        # 모델을 학습 모드로 설정\n",
        "        model.train()\n",
        "        runningLoss = 0.0\n",
        "        runningCorrects = 0\n",
        "\n",
        "        # 훈련 데이터 반복 학습\n",
        "        for inputs, labels in trainLoader:\n",
        "            # 이미지와 라벨(클래스)\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # 기존 그래디언트 초기화\n",
        "            optimizer.zero_grad()\n",
        "            # 모델 forward pass\n",
        "            outputs = model(inputs)\n",
        "            # 손실함수 계산 (출력, 정답)\n",
        "            loss = criterion(outputs, labels)\n",
        "            # 역전파 학습\n",
        "            loss.backward()\n",
        "            # 파라미터 업데이트\n",
        "            optimizer.step()\n",
        "\n",
        "            # 예측값 계산\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            # 손실 합산\n",
        "            runningLoss += loss.item() * inputs.size(0)\n",
        "            # 정확도 합산\n",
        "            runningCorrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # 반복 횟수 단위로 Train 평균 손실 및 정확도 계산\n",
        "        epochLoss = runningLoss / len(trainLoader.dataset)\n",
        "        epochAcc = runningCorrects.double() / len(trainLoader.dataset)\n",
        "        print(f\"Epoch {epoch+1}/{numEpochs} - Train Loss: {epochLoss:.4f} Acc: {epochAcc:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        # 모델을 평가 모드로 설정\n",
        "        model.eval()\n",
        "        valLoss = 0.0\n",
        "        valCorrects = 0\n",
        "\n",
        "        # 그래디언트 비활성화\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in valLoader:\n",
        "                # 이미지와 라벨(클래스)\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                # 모델 forward pass\n",
        "                outputs = model(inputs)\n",
        "                # 손실함수 계산 (출력, 정답)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # 예측값 계산\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                # 손실 합산\n",
        "                valLoss += loss.item() * inputs.size(0)\n",
        "                # 정확도 합산\n",
        "                valCorrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # 반복 횟수 단위로 Validation 평균 손실 및 정확도 계산\n",
        "        valLoss /= len(valLoader.dataset)\n",
        "        val_acc = valCorrects.double() / len(valLoader.dataset)\n",
        "        print(f\"Validation Loss: {valLoss:.4f} Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # Scheduler: Validation Loss 기반으로 학습률 조정\n",
        "        scheduler.step(valLoss)\n",
        "\n",
        "        # Early Stopping\n",
        "        # 개선이 되면\n",
        "        if valLoss < best_val_loss:\n",
        "            best_val_loss = valLoss\n",
        "            counter = 0\n",
        "            torch.save(model, best_model_path)\n",
        "            print(f\"Renewal best model: {best_val_loss:.4f}\")\n",
        "        # 개선이 안되면\n",
        "        else:\n",
        "            counter += 1\n",
        "            print(f\"No improvement in {counter}/{patience} epochs\")\n",
        "            if counter >= patience:\n",
        "                break"
      ],
      "metadata": {
        "id": "JEmAA8AGj-IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def TestModel(model, testLoader):\n",
        "    all_preds = []\n",
        "    all_probs = []  # AUC 계산용 softmax 확률\n",
        "    all_labels = []\n",
        "\n",
        "    testCorrects = 0\n",
        "    testLoss = 0.0\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testLoader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # 예측 클래스\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            # softmax 확률 (클래스 1의 확률만)\n",
        "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
        "\n",
        "            testLoss += loss.item() * inputs.size(0)\n",
        "            testCorrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # 평균 계산\n",
        "    testLoss /= len(testLoader.dataset)\n",
        "    testAcc = testCorrects.double() / len(testLoader.dataset)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    precision = precision_score(all_labels, all_preds, average='macro')\n",
        "    recall = recall_score(all_labels, all_preds, average='macro')\n",
        "    auc = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "    print(f\"Test Accuracy  : {testAcc:.4f}\")\n",
        "    print(f\"Test Loss      : {testLoss:.4f}\")\n",
        "    print(f\"ROC-AUC        : {auc:.4f}\")\n",
        "    print(f\"Precision      : {precision:.4f}\")\n",
        "    print(f\"Recall         : {recall:.4f}\")\n",
        "    print(f\"F1-score       : {f1:.4f}\")\n",
        "\n",
        "    return testAcc.item(), testLoss, auc, precision, recall, f1"
      ],
      "metadata": {
        "id": "NuuvedRxBo8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/weiaicunzai/pytorch-cifar100/blob/master/models/inceptionv4.py"
      ],
      "metadata": {
        "id": "kW8htqg0pAUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Inception-V4 모델 생성 및 정의 '''\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class BasicConv2d(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, **kwargs):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size, bias = False, **kwargs),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    return x\n",
        "\n",
        "class Stem(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "        BasicConv2d(3,32,3,stride = 2, padding = 0), # 149x149x32\n",
        "        BasicConv2d(32,32,3,padding = 0), # 147x147x32\n",
        "        BasicConv2d(32,64,3,padding = 1) # 147x147x64\n",
        "    )\n",
        "\n",
        "    self.branch_1_pool = nn.MaxPool2d(3,stride=2,padding=0)\n",
        "    self.branch_1_conv = BasicConv2d(64,96,3,stride=2,padding=0)\n",
        "    # 73x73x160\n",
        "\n",
        "    self.branch_2a = nn.Sequential(\n",
        "        BasicConv2d(160,64,1,stride = 1, padding = 0),\n",
        "        BasicConv2d(64,96,3,stride = 1, padding=0)\n",
        "    )\n",
        "    self.branch_2b = nn.Sequential(\n",
        "        BasicConv2d(160,64,1,stride = 1, padding = 0),\n",
        "        BasicConv2d(64,64,(7,1), stride = 1, padding = (3,0)),\n",
        "        BasicConv2d(64,64,(1,7), stride = 1, padding = (0,3)),\n",
        "        BasicConv2d(64,96,3,stride = 1, padding=0)\n",
        "    )\n",
        "    # 71x71x192\n",
        "\n",
        "    self.branch_3_pool = nn.MaxPool2d(3,stride = 2, padding = 0)\n",
        "    self.branch_3_conv = BasicConv2d(192,192,3,stride = 2,padding = 0)\n",
        "    # 35x35x384\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "\n",
        "    x = [\n",
        "        self.branch_1_pool(x),\n",
        "        self.branch_1_conv(x)\n",
        "    ]\n",
        "    x = torch.cat(x,1)\n",
        "\n",
        "    x = [\n",
        "        self.branch_2a(x),\n",
        "        self.branch_2b(x)\n",
        "    ]\n",
        "    x = torch.cat(x,1)\n",
        "\n",
        "    x = [\n",
        "        self.branch_3_pool(x),\n",
        "        self.branch_3_conv(x)\n",
        "    ]\n",
        "    x = torch.cat(x,1)\n",
        "\n",
        "    return x\n",
        "\n",
        "class InceptionA(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.branch_a = nn.Sequential(\n",
        "        nn.AvgPool2d(3,stride=1,padding=1),\n",
        "        BasicConv2d(384,96,1)\n",
        "    ) # 35x35x96\n",
        "    self.branch_b = BasicConv2d(384,96,1,stride=1,padding=0) # 35x35x96\n",
        "    self.branch_c = nn.Sequential(\n",
        "        BasicConv2d(384,64,1,stride=1,padding=0),\n",
        "        BasicConv2d(64,96,3,stride=1,padding=1)\n",
        "    ) # 35x35x96\n",
        "    self.branch_d = nn.Sequential(\n",
        "        BasicConv2d(384,64,1,stride=1,padding=0),\n",
        "        BasicConv2d(64,96,3,stride=1,padding=1),\n",
        "        BasicConv2d(96,96,3,stride=1,padding=1)\n",
        "    ) # 35x35x96\n",
        "    # 35x35x384\n",
        "  def forward(self, x):\n",
        "    x = [\n",
        "        self.branch_a(x),\n",
        "        self.branch_b(x),\n",
        "        self.branch_c(x),\n",
        "        self.branch_d(x)\n",
        "    ]\n",
        "    x = torch.cat(x,1)\n",
        "\n",
        "    return x\n",
        "\n",
        "class ReductionA(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # k = 192, l = 224, m = 256, n = 384\n",
        "    self.branch_a = nn.MaxPool2d(3,stride=2,padding=0) # 17x17x384\n",
        "    self.branch_b = BasicConv2d(384,384,3,stride=2,padding=0) # 17x17x384\n",
        "    self.branch_c = nn.Sequential(\n",
        "        BasicConv2d(384,192,1),\n",
        "        BasicConv2d(192,224,3,padding=1),\n",
        "        BasicConv2d(224,256,3,stride=2,padding=0)\n",
        "    ) # 17x17x256\n",
        "    # 17x17x1024\n",
        "  def forward(self, x):\n",
        "    x = [\n",
        "        self.branch_a(x),\n",
        "        self.branch_b(x),\n",
        "        self.branch_c(x)\n",
        "    ]\n",
        "    x = torch.cat(x,1)\n",
        "\n",
        "    return x\n",
        "\n",
        "class InceptionB(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.branch_a = nn.Sequential(\n",
        "        nn.AvgPool2d(3,stride=1,padding=1),\n",
        "        BasicConv2d(1024,128,1)\n",
        "    ) # 17x17x128\n",
        "    self.branch_b = BasicConv2d(1024,384,1) # 17x17x384\n",
        "    self.branch_c = nn.Sequential(\n",
        "        BasicConv2d(1024,192,1),\n",
        "        BasicConv2d(192,224,(1,7),padding=(0,3)),\n",
        "        BasicConv2d(224,256,(7,1),padding=(3,0))\n",
        "    ) # 17x17x256\n",
        "    self.branch_d = nn.Sequential(\n",
        "        BasicConv2d(1024,192,1,stride=1,padding=0),\n",
        "        BasicConv2d(192,192,(1,7),stride=1,padding=(3,0)),\n",
        "        BasicConv2d(192,224,(7,1),stride=1,padding=(0,3)),\n",
        "        BasicConv2d(224,224,(1,7),stride=1,padding=(3,0)),\n",
        "        BasicConv2d(224,256,(7,1),stride=1,padding=(0,3))\n",
        "    ) # 17x17x256\n",
        "  # 17x17x1024\n",
        "  def forward(self, x):\n",
        "    x = [\n",
        "        self.branch_a(x),\n",
        "        self.branch_b(x),\n",
        "        self.branch_c(x),\n",
        "        self.branch_d(x)\n",
        "    ]\n",
        "    x = torch.cat(x,1)\n",
        "\n",
        "    return x\n",
        "\n",
        "class ReductionB(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.branch_a = nn.MaxPool2d(3,stride=2,padding=0) # 8x8x1024\n",
        "    self.branch_b = nn.Sequential(\n",
        "        BasicConv2d(1024,192,1),\n",
        "        BasicConv2d(192,192,3,stride=2,padding=0)\n",
        "    ) # 8x8x192\n",
        "    self.branch_c = nn.Sequential(\n",
        "        BasicConv2d(1024,256,1),\n",
        "        BasicConv2d(256,256,(1,7),padding = (3,0)),\n",
        "        BasicConv2d(256,320,(7,1),padding = (0,3)),\n",
        "        BasicConv2d(320,320,3,stride=2,padding=0)\n",
        "    ) # 8x8x320\n",
        "  # 8x8x1536\n",
        "  def forward(self, x):\n",
        "    x = [\n",
        "        self.branch_a(x),\n",
        "        self.branch_b(x),\n",
        "        self.branch_c(x)\n",
        "    ]\n",
        "    x = torch.cat(x,1)\n",
        "\n",
        "    return x\n",
        "\n",
        "class InceptionC(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.branch_a = nn.Sequential(\n",
        "        nn.AvgPool2d(3,stride=1,padding=1),\n",
        "        BasicConv2d(1536,256,1)\n",
        "    ) # 8x8x256\n",
        "    self.branch_b = BasicConv2d(1536,256,1) # 8x8x256\n",
        "    self.branch_c = BasicConv2d(1536,384,1) # 8x8x384\n",
        "    self.branch_c_a = BasicConv2d(384,256,(1,3),padding=(0,1))\n",
        "    self.branch_c_b = BasicConv2d(384,256,(3,1),padding=(1,0))\n",
        "    # 8x8x512\n",
        "    self.branch_d = nn.Sequential(\n",
        "        BasicConv2d(1536,384,1),\n",
        "        BasicConv2d(384,448,(1,3),padding=(0,1)),\n",
        "        BasicConv2d(448,512,(3,1),padding=(1,0))\n",
        "    ) # 8x8x512\n",
        "    self.branch_d_a = BasicConv2d(512,256,(3,1),padding=(1,0))\n",
        "    self.branch_d_b = BasicConv2d(512,256,(1,3),padding=(0,1))\n",
        "    # 8x8x512\n",
        "    # 8x8x1536\n",
        "  def forward(self, x):\n",
        "    t = self.branch_c(x)\n",
        "    c = [\n",
        "        self.branch_c_a(t),\n",
        "        self.branch_c_b(t)\n",
        "    ]\n",
        "\n",
        "    t = self.branch_d(x)\n",
        "    d = [\n",
        "        self.branch_d_a(t),\n",
        "        self.branch_d_b(t)\n",
        "    ]\n",
        "\n",
        "    a = self.branch_a(x)\n",
        "    b = self.branch_b(x)\n",
        "    c = torch.cat(c,1)\n",
        "    d = torch.cat(d,1)\n",
        "\n",
        "    x = [a,b,c,d]\n",
        "    x = torch.cat(x,1)\n",
        "\n",
        "    return x\n",
        "\n",
        "class InceptionV4(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.stem = Stem()\n",
        "\n",
        "    self.inceptionA = nn.Sequential(\n",
        "        InceptionA(),\n",
        "        InceptionA(),\n",
        "        InceptionA(),\n",
        "        InceptionA()\n",
        "    )\n",
        "\n",
        "    self.reductionA = ReductionA()\n",
        "\n",
        "    self.inceptionB = nn.Sequential(\n",
        "        InceptionB(),\n",
        "        InceptionB(),\n",
        "        InceptionB(),\n",
        "        InceptionB(),\n",
        "        InceptionB(),\n",
        "        InceptionB(),\n",
        "        InceptionB()\n",
        "    )\n",
        "\n",
        "    self.reductionB = ReductionB()\n",
        "\n",
        "    self.inceptionC = nn.Sequential(\n",
        "        InceptionC(),\n",
        "        InceptionC(),\n",
        "        InceptionC()\n",
        "    )\n",
        "\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.dropout = nn.Dropout(0.2*use_dropout)\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(1536, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2*use_dropout),\n",
        "        nn.Linear(256, 2)\n",
        "    )\n",
        "\n",
        "    self._initialize_weights()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.stem(x)\n",
        "    x = self.inceptionA(x)\n",
        "    x = self.reductionA(x)\n",
        "    x = self.inceptionB(x)\n",
        "    x = self.reductionB(x)\n",
        "    x = self.inceptionC(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "  def _initialize_weights(self):\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "      elif isinstance(m, nn.BatchNorm2d):\n",
        "        nn.init.constant_(m.weight, 1)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "      elif isinstance(m, nn.Linear):\n",
        "        nn.init.normal_(m.weight, 0, 0.01)\n",
        "        nn.init.constant_(m.bias, 0)"
      ],
      "metadata": {
        "id": "tMRDkPpas-5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check Stem\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "x = torch.randn((3, 3, 299, 299)).to(device)\n",
        "model = Stem().to(device)\n",
        "output_Stem = model(x)\n",
        "print('Input size:', x.size())\n",
        "print('Stem output size:', output_Stem.size())"
      ],
      "metadata": {
        "id": "tv1mdFlxHLkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = InceptionA().to(device)\n",
        "output_incA = model(output_Stem)\n",
        "print('Input size:', output_Stem.size())\n",
        "print('output size:', output_incA.size())"
      ],
      "metadata": {
        "id": "xZK-W1z6a5f0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ReductionA().to(device)\n",
        "output_resA = model(output_incA)\n",
        "print('Input size:', output_incA.size())\n",
        "print('output size:', output_resA.size())"
      ],
      "metadata": {
        "id": "1i-Y3YmncSCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = InceptionB().to(device)\n",
        "output_incB = model(output_resA)\n",
        "print('Input size:', output_resA.size())\n",
        "print('output size:', output_incB.size())"
      ],
      "metadata": {
        "id": "uYc9jwPidU06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ReductionB().to(device)\n",
        "output_resB = model(output_incB)\n",
        "print('Input size:', output_incB.size())\n",
        "print('output size:', output_resB.size())"
      ],
      "metadata": {
        "id": "orpoFbijf3Ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = InceptionC().to(device)\n",
        "output_incC = model(output_resB)\n",
        "print('Input size:', output_resB.size())\n",
        "print('output size:', output_incC.size())"
      ],
      "metadata": {
        "id": "fnjzfUX0hH3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = InceptionV4().to(device)\n",
        "summary(model, (3,299,299), device=device.type)"
      ],
      "metadata": {
        "id": "C5XG2FMIlqEN",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습 및 테스트"
      ],
      "metadata": {
        "id": "4rXgBKTrFQo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,2):\n",
        "  # 모델 불러오기\n",
        "  model = InceptionV4().to(device)\n",
        "\n",
        "  # CrossEntropyLoss로 손실 함수 설정\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  # Adam으로 옵티마이저로 사용 (filter를 통해 require_grad = True, 동결되지 않은 것만 업데이트)\n",
        "  # weight_decay = 4e-5 : L2 정규화 적용으로 과적합 방지 / 논문 l2 정규화 값 0.00004\n",
        "  optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=4e-5*use_l2)\n",
        "\n",
        "  # 학습률 스케줄러 설정\n",
        "  # 검증 손실이 줄어들지 않으면 learning rate 줄임 (수렴 및 안정화)\n",
        "  # min 모드 : 손실이 최소화되지 않으면 작동 / factor : 학습률을 x배 줄임 / patience : x번 학습동안 개선되지 않으면 발동 / verbose : 메시지 출력\n",
        "  scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "  # Train 모델 실행\n",
        "  TrainModel(model, criterion, optimizer, scheduler, trainLoader, valLoader, numEpochs=20, patience=5)\n",
        "\n",
        "  os.rename(f\"/content/drive/MyDrive/model/Inception v4 초기학습/{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model.pth\", f\"/content/drive/MyDrive/model/Inception v4 초기학습/{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model_{i+1}.pth\")"
      ],
      "metadata": {
        "id": "Ko7sT-B2d9KT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82b74977-e430-4ebe-a3ea-0e27df7b9396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - Train Loss: 0.6539 Acc: 0.6047\n",
            "Validation Loss: 0.5598 Acc: 0.7074\n",
            "Renewal best model: 0.5598\n",
            "Epoch 2/20 - Train Loss: 0.4860 Acc: 0.7726\n",
            "Validation Loss: 0.5461 Acc: 0.7539\n",
            "Renewal best model: 0.5461\n",
            "Epoch 3/20 - Train Loss: 0.4276 Acc: 0.8017\n",
            "Validation Loss: 0.5074 Acc: 0.7907\n",
            "Renewal best model: 0.5074\n",
            "Epoch 4/20 - Train Loss: 0.3734 Acc: 0.8295\n",
            "Validation Loss: 0.7307 Acc: 0.7616\n",
            "No improvement in 1/5 epochs\n",
            "Epoch 5/20 - Train Loss: 0.3535 Acc: 0.8366\n",
            "Validation Loss: 0.4621 Acc: 0.7771\n",
            "Renewal best model: 0.4621\n",
            "Epoch 6/20 - Train Loss: 0.2672 Acc: 0.8747\n",
            "Validation Loss: 0.4927 Acc: 0.8043\n",
            "No improvement in 1/5 epochs\n",
            "Epoch 7/20 - Train Loss: 0.2236 Acc: 0.9089\n",
            "Validation Loss: 0.6159 Acc: 0.7829\n",
            "No improvement in 2/5 epochs\n",
            "Epoch 8/20 - Train Loss: 0.2468 Acc: 0.8915\n",
            "Validation Loss: 0.5380 Acc: 0.8178\n",
            "No improvement in 3/5 epochs\n",
            "Epoch 9/20 - Train Loss: 0.2290 Acc: 0.9025\n",
            "Validation Loss: 0.6265 Acc: 0.7888\n",
            "No improvement in 4/5 epochs\n",
            "Epoch 10/20 - Train Loss: 0.1207 Acc: 0.9580\n",
            "Validation Loss: 0.4397 Acc: 0.8391\n",
            "Renewal best model: 0.4397\n",
            "Epoch 11/20 - Train Loss: 0.0570 Acc: 0.9871\n",
            "Validation Loss: 0.4467 Acc: 0.8372\n",
            "No improvement in 1/5 epochs\n",
            "Epoch 12/20 - Train Loss: 0.0338 Acc: 0.9961\n",
            "Validation Loss: 0.4636 Acc: 0.8450\n",
            "No improvement in 2/5 epochs\n",
            "Epoch 13/20 - Train Loss: 0.0220 Acc: 0.9987\n",
            "Validation Loss: 0.4822 Acc: 0.8450\n",
            "No improvement in 3/5 epochs\n",
            "Epoch 14/20 - Train Loss: 0.0156 Acc: 1.0000\n",
            "Validation Loss: 0.5009 Acc: 0.8430\n",
            "No improvement in 4/5 epochs\n",
            "Epoch 15/20 - Train Loss: 0.0133 Acc: 1.0000\n",
            "Validation Loss: 0.5019 Acc: 0.8450\n",
            "No improvement in 5/5 epochs\n",
            "Epoch 1/20 - Train Loss: 0.6408 Acc: 0.6298\n",
            "Validation Loss: 0.5626 Acc: 0.7306\n",
            "Renewal best model: 0.5626\n",
            "Epoch 2/20 - Train Loss: 0.4896 Acc: 0.7636\n",
            "Validation Loss: 0.5877 Acc: 0.7364\n",
            "No improvement in 1/5 epochs\n",
            "Epoch 3/20 - Train Loss: 0.4182 Acc: 0.8165\n",
            "Validation Loss: 0.5056 Acc: 0.7713\n",
            "Renewal best model: 0.5056\n",
            "Epoch 4/20 - Train Loss: 0.3575 Acc: 0.8501\n",
            "Validation Loss: 0.4644 Acc: 0.8275\n",
            "Renewal best model: 0.4644\n",
            "Epoch 5/20 - Train Loss: 0.3050 Acc: 0.8760\n",
            "Validation Loss: 0.5519 Acc: 0.7810\n",
            "No improvement in 1/5 epochs\n",
            "Epoch 6/20 - Train Loss: 0.2960 Acc: 0.8831\n",
            "Validation Loss: 0.4494 Acc: 0.8159\n",
            "Renewal best model: 0.4494\n",
            "Epoch 7/20 - Train Loss: 0.2333 Acc: 0.9089\n",
            "Validation Loss: 0.5894 Acc: 0.8043\n",
            "No improvement in 1/5 epochs\n",
            "Epoch 8/20 - Train Loss: 0.2650 Acc: 0.8902\n",
            "Validation Loss: 0.4687 Acc: 0.8101\n",
            "No improvement in 2/5 epochs\n",
            "Epoch 9/20 - Train Loss: 0.1745 Acc: 0.9380\n",
            "Validation Loss: 0.6459 Acc: 0.8023\n",
            "No improvement in 3/5 epochs\n",
            "Epoch 10/20 - Train Loss: 0.1863 Acc: 0.9270\n",
            "Validation Loss: 0.5205 Acc: 0.8140\n",
            "No improvement in 4/5 epochs\n",
            "Epoch 11/20 - Train Loss: 0.1428 Acc: 0.9457\n",
            "Validation Loss: 0.3754 Acc: 0.8488\n",
            "Renewal best model: 0.3754\n",
            "Epoch 12/20 - Train Loss: 0.0642 Acc: 0.9864\n",
            "Validation Loss: 0.3830 Acc: 0.8508\n",
            "No improvement in 1/5 epochs\n",
            "Epoch 13/20 - Train Loss: 0.0398 Acc: 0.9922\n",
            "Validation Loss: 0.3971 Acc: 0.8527\n",
            "No improvement in 2/5 epochs\n",
            "Epoch 14/20 - Train Loss: 0.0288 Acc: 0.9929\n",
            "Validation Loss: 0.4089 Acc: 0.8547\n",
            "No improvement in 3/5 epochs\n",
            "Epoch 15/20 - Train Loss: 0.0218 Acc: 0.9942\n",
            "Validation Loss: 0.4215 Acc: 0.8508\n",
            "No improvement in 4/5 epochs\n",
            "Epoch 16/20 - Train Loss: 0.0184 Acc: 0.9961\n",
            "Validation Loss: 0.4228 Acc: 0.8508\n",
            "No improvement in 5/5 epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model.pth\")\n",
        "for i in range(2):\n",
        "  best_model_path = f\"/content/drive/MyDrive/model/Inception v4 초기학습/{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model_{i+1}.pth\"\n",
        "  model = torch.load(best_model_path, weights_only=False)\n",
        "  model.to(device)\n",
        "\n",
        "  # 테스트\n",
        "  result = TestModel(model, testLoader)\n",
        "  print()"
      ],
      "metadata": {
        "id": "Zov9aTHBePqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2411d1a-ddd0-4380-ea02-e4dc9be77fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1110_best_model.pth\n",
            "Test Accuracy  : 0.8779\n",
            "Test Loss      : 0.3697\n",
            "ROC-AUC        : 0.9343\n",
            "Precision      : 0.8805\n",
            "Recall         : 0.8786\n",
            "F1-score       : 0.8777\n",
            "\n",
            "Test Accuracy  : 0.8585\n",
            "Test Loss      : 0.3948\n",
            "ROC-AUC        : 0.9257\n",
            "Precision      : 0.8602\n",
            "Recall         : 0.8591\n",
            "F1-score       : 0.8584\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Rum6jK0hF9R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}