{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "collapsed_sections": [
        "j2f4Vu4gAM42"
      ],
      "authorship_tag": "ABX9TyNZbFKQRvhUNnaeKf7Wlkki",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bisil2/AI1_Final_Project/blob/main/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A51_%EB%AA%A8%EB%8D%B8_%ED%95%99%EC%8A%B5(Inception_v4_%EC%82%AC%EC%A0%84%ED%95%99%EC%8A%B5).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 02) 정상/감염 이진분류 모델 학습(ResNet50)"
      ],
      "metadata": {
        "id": "z1juJZgh_8Z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_background = 1\n",
        "use_agumentation = 1\n",
        "use_dropout = 1\n",
        "use_freezing = 1\n",
        "use_l2 = 0"
      ],
      "metadata": {
        "id": "70f-qo0wj-Gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라이브러리 설치 및 Import"
      ],
      "metadata": {
        "id": "j2f4Vu4gAM42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' 패키지 설치 '''\n",
        "!pip install torch torchvision\n",
        "\n",
        "# =============================\n",
        "# torch : 모델 실행, 학습, 추론에 필수적인 PyTorch 프레임워크\n",
        "# torchvision : 이미지 처리 관련 도구 제공\n",
        "# ============================="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3JaYUpQAP6e",
        "outputId": "307887d2-6c87-4c10-84bd-b205fe79a80d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Google Drive 연동'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "'''필수 라이브러리 import'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import zipfile\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwU4aNSCAR5Y",
        "outputId": "3b4d5f13-fb35-4d66-fd37-231ebe336eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 불러오기"
      ],
      "metadata": {
        "id": "pWHCwWFEAltP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Label 데이터 불러오기'''\n",
        "rawdata = pd.read_csv(\"/content/drive/MyDrive/data/rawdata.csv\")"
      ],
      "metadata": {
        "id": "HAzCnRGJApPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Image 데이터 불러오기'''\n",
        "if use_background:\n",
        "  zipName = 'data'\n",
        "else:\n",
        "  zipName = 'raw'\n",
        "\n",
        "# data 폴더 생성\n",
        "targetPath = '/content/data/'\n",
        "os.makedirs(targetPath, exist_ok=True)\n",
        "\n",
        "# 압축 파일 content로 복사 => content에 있으면 처리속도가 비교적 빠름\n",
        "rootZip = f'/content/drive/MyDrive/data/{zipName}.zip'\n",
        "targetZip = f'/content/{zipName}.zip'\n",
        "shutil.copyfile(rootZip, targetZip)\n",
        "\n",
        "# zipfile.ZipFile로 압축 파일을 열고, 압축된 모든 파일을 targetPath로 이동(압축 해제)\n",
        "with zipfile.ZipFile(targetZip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(targetPath)"
      ],
      "metadata": {
        "id": "-I56jW4lAsiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 Split"
      ],
      "metadata": {
        "id": "H0AfAUzFAt3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Train:Val:Test = 6:2:2 분할'''\n",
        "# rawdata를 분할. train:(val+test) = 6:4\n",
        "train, temp = train_test_split(rawdata, test_size=0.4, random_state=1)\n",
        "\n",
        "# rawdata를 분할. val:test = 5:5\n",
        "val, test = train_test_split(temp, test_size=0.5, random_state=1)"
      ],
      "metadata": {
        "id": "OmEJwNX7BAqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋 클래스, Transform 생성"
      ],
      "metadata": {
        "id": "Wss5QZOvD17G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' DataSet 클래스 정의 '''\n",
        "# =============================\n",
        "# 목적 : DataFrame에 저장된 이미지 경로와 라벨 등을 불러오고, 전처리 후 (image, label) 리턴\n",
        "# 매개변수(?)\n",
        "#  - dataframe : 이미지 파일 이름/클래스 등이 포함된 변수\n",
        "#  - rootDir : 이미지들이 저장된 경로\n",
        "#  - transform : torchvision.transforms를 사용한 이미지 전처리 파이프라인(전처리 묶음? 정도로 이해하면 될 듯)\n",
        "# =============================\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, dataframe, rootDir, transform=None):\n",
        "    self.dataframe = dataframe\n",
        "    self.rootDir = rootDir\n",
        "    self.transform = transform\n",
        "\n",
        "  # 데이터셋의 총 샘플 수 반환\n",
        "  def __len__(self):\n",
        "    return len(self.dataframe)\n",
        "\n",
        "  # idx번째 데이터 리턴\n",
        "  def __getitem__(self, idx):\n",
        "    # DataFrame의 idx번째 행을 row에 저장\n",
        "    row = self.dataframe.iloc[idx]\n",
        "    # 이미지 경로 불러오기(row['image']는 파일명이므로, 상위 경로와 더해줌; 파일 이름이 '.JPG'로 된 경우도 있어서 통일)\n",
        "    imgName = os.path.join(self.rootDir, row['image'].replace('.JPG', '.jpg'))\n",
        "\n",
        "    # 이미지 파일을 열고, RGB로 변환\n",
        "    image = Image.open(imgName).convert('RGB')\n",
        "\n",
        "    # trasform이 정의되어 있다면, 전처리 적용\n",
        "    if self.transform:\n",
        "        image = self.transform(image)\n",
        "\n",
        "    # 라벨 저장\n",
        "    label = row['class']\n",
        "\n",
        "    # (전처리된 이미지, 라벨) 리턴\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "VC_MaxdUD70V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Transform 정의'''\n",
        "# train, val, test 용도에 따라 전처리를 다르게 적용\n",
        "if use_agumentation:\n",
        "  transform = {\n",
        "      'train': transforms.Compose([\n",
        "          # 이미지를 224x224로 통일 (ResNet50 입력 크기)\n",
        "          transforms.Resize((224, 224)),\n",
        "          # 확률적으로 이미지를 좌우 반전 (데이터 증강)\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          # -15 ~ +15도 사이로 랜덤 회전 (데이터 증강)\n",
        "          transforms.RandomRotation(15),\n",
        "          # 밝기, 대비, 채도 랜덤 조절 (데이터 증강)\n",
        "          transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "          # 10 % 비율로 좌우 또는 상화 랜덤 이동 (데이터 증강)\n",
        "          transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "          # PIL 이미지를 Tensor 형식으로 변환 (0~255 >> 0~1 실수형)\n",
        "          transforms.ToTensor(),\n",
        "          # 평균 및 표준편차를 기준으로 정규화 (Image Net으로 사전 학습도니 모델과 일치시키기 위해)\n",
        "          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "      ]),\n",
        "      'val': transforms.Compose([\n",
        "          # 이미지를 224x224로 통일 (ResNet50 입력 크기)\n",
        "          transforms.Resize((224, 224)),\n",
        "          # PIL 이미지를 Tensor 형식으로 변환 (0~255 >> 0~1 실수형)\n",
        "          transforms.ToTensor(),\n",
        "          # 평균 및 표준편차를 기준으로 정규화 (Image Net으로사전 학습도니 모델과 일치시키기 위해)\n",
        "          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "      ]),\n",
        "      'test': transforms.Compose([ # val과 동일/ train과 달리 평가 용도기 때문에 val과 test에는 데이터 증강이 없음.\n",
        "          transforms.Resize((224, 224)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "      ])\n",
        "  }\n",
        "else:\n",
        "  transform = {\n",
        "      'train': transforms.Compose([\n",
        "          # 이미지를 224x224로 통일 (ResNet50 입력 크기)\n",
        "          transforms.Resize((224, 224)),\n",
        "          # PIL 이미지를 Tensor 형식으로 변환 (0~255 >> 0~1 실수형)\n",
        "          transforms.ToTensor(),\n",
        "          # 평균 및 표준편차를 기준으로 정규화 (Image Net으로 사전 학습도니 모델과 일치시키기 위해)\n",
        "          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "      ]),\n",
        "      'val': transforms.Compose([\n",
        "          # 이미지를 224x224로 통일 (ResNet50 입력 크기)\n",
        "          transforms.Resize((224, 224)),\n",
        "          # PIL 이미지를 Tensor 형식으로 변환 (0~255 >> 0~1 실수형)\n",
        "          transforms.ToTensor(),\n",
        "          # 평균 및 표준편차를 기준으로 정규화 (Image Net으로사전 학습도니 모델과 일치시키기 위해)\n",
        "          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "      ]),\n",
        "      'test': transforms.Compose([ # val과 동일/ train과 달리 평가 용도기 때문에 val과 test에는 데이터 증강이 없음.\n",
        "          transforms.Resize((224, 224)),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "      ])\n",
        "  }"
      ],
      "metadata": {
        "id": "CK15qzZgCqQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset 불러오기\n",
        "trainDataset = CustomDataset(train, '/content/data', transform=transform['train'])\n",
        "valDataset = CustomDataset(val, '/content/data', transform=transform['val'])\n",
        "testDataset = CustomDataset(test, '/content/data', transform=transform['test'])\n",
        "\n",
        "# DataLoader 불러오기\n",
        "trainLoader = DataLoader(trainDataset, batch_size=32, shuffle=False)\n",
        "valLoader = DataLoader(valDataset, batch_size=32, shuffle=False)\n",
        "testLoader = DataLoader(testDataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "463sGLomlNym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습, 테스트 메소드 정의"
      ],
      "metadata": {
        "id": "P1VaSpJ4EMW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' ResNet50 모델 생성 및 정의 '''\n",
        "\n",
        "# 사용할 디바이스 설정 : GPU(cuda)가 가능하면 GPU, 아니면 CPU 사용\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# =============================\n",
        "# 목적 : 모델을 불러오고 재정의\n",
        "# =============================\n",
        "def create_model():\n",
        "    # 사전 학습된 ResNet50 모델 불러오기\n",
        "    # ImageNet으로 학습된 가중치를 불러와서 학습 시간을 줄이고 성능 향상을 기대할 수 있음.\n",
        "    model = models.resnet50(pretrained=True)\n",
        "\n",
        "    # 모델의 일부 레이어를 freeze : 특정 레이어의 가중치를 고정하여 학습 제외\n",
        "    # Optimal Layer Selection on Deep Convolutional Neural Networks Using Backward Freezing and Binary Search에서 51개 레이어를 동결하는게 가장 효율이 좋더라~\n",
        "    # 이유는 데이터가 작기 때문에 과적합을 방지하기 위함 >> 전반부는 묶어두고, 후반부의 레이어만 학습시키기 위해서\n",
        "    all_params = list(model.named_parameters())\n",
        "\n",
        "    if use_freezing:\n",
        "      # 앞의 51개 파라미터는 동결 (requires_grad=False)\n",
        "      for name, param in all_params[:51]:\n",
        "          param.requires_grad = False\n",
        "\n",
        "      # 나머지는 학습 대상\n",
        "      for name, param in all_params[51:]:\n",
        "          param.requires_grad = True\n",
        "    else:\n",
        "      for name, param in all_params:\n",
        "          param.requires_grad = True\n",
        "\n",
        "    # 기존의 fully connected layer는 제거하고, 새로운 분류기로 대체\n",
        "    # 기존 fc 레이어의 feature 수 불러오기\n",
        "    num_features = model.fc.in_features\n",
        "    # 새로운 fc 레이어 정의 (Sequantial)\n",
        "    if use_dropout:\n",
        "      model.fc = nn.Sequential(\n",
        "          # 기존 특성 수 >> 256 차원으로 축소\n",
        "          nn.Linear(num_features, 256),\n",
        "          # 활성화 함수\n",
        "          nn.ReLU(),\n",
        "          # 일부 뉴런을 50% 확률로 0으로 설정 >> 너무 과적합되면 일반화에 방해가 되기 때문에\n",
        "          nn.Dropout(0.5),\n",
        "          # 256 -> 2 차원으로 축소 (2개 클래스 분류를 위한 출력층)\n",
        "          nn.Linear(256, 2),\n",
        "      )\n",
        "    else:\n",
        "      model.fc = nn.Sequential(\n",
        "          # 기존 특성 수 >> 256 차원으로 축소\n",
        "          nn.Linear(num_features, 256),\n",
        "          # 활성화 함수\n",
        "          nn.ReLU(),\n",
        "          # 256 -> 2 차원으로 축소 (2개 클래스 분류를 위한 출력층)\n",
        "          nn.Linear(256, 2),\n",
        "      )\n",
        "\n",
        "    # 모델을 지정한 디바이스로 이동\n",
        "    return model.to(device)"
      ],
      "metadata": {
        "id": "55euDTe-GL3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' 학습 모델 '''\n",
        "# =============================\n",
        "# 목적 : 모델 학습\n",
        "# 1단계 : 0~51 layer 동결 학습\n",
        "# 2단계 : 전체 layer 학습\n",
        "# Early Stopping : val loss가 6번 이상 개선이 안될 경우, 종료\n",
        "# =============================\n",
        "def TrainModel(model, criterion, optimizer, scheduler, trainLoader, valLoader, numEpochs=12, patience=6):\n",
        "    # Early Stopping 관련 변수\n",
        "    # loss 기준값을 최댓값으로 설정\n",
        "    best_val_loss = float('inf')\n",
        "    # early stopping counter 0으로 설정\n",
        "    counter = 0\n",
        "    # best model 저장 경로 설정\n",
        "    best_model_path = f\"/content/drive/MyDrive/model/{use_background}{use_agumentation}{use_dropout}{use_freezing}{use_l2}_best_model.pth\"\n",
        "\n",
        "    # Backbone 동결 상태에서 fc layer만 학습\n",
        "    print(\"Stage 1: Training fc layer only (Backbone frozen)\")\n",
        "    for epoch in range(numEpochs//2):\n",
        "        # Train\n",
        "        # 모델을 학습 모드로 설정\n",
        "        model.train()\n",
        "        runningLoss = 0.0\n",
        "        runningCorrects = 0\n",
        "\n",
        "        # 훈련 데이터 반복 학습\n",
        "        for inputs, labels in trainLoader:\n",
        "            # 이미지와 라벨(클래스)\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # 기존 그래디언트 초기화\n",
        "            optimizer.zero_grad()\n",
        "            # 모델 forward pass\n",
        "            outputs = model(inputs)\n",
        "            # 손실함수 계산 (출력, 정답)\n",
        "            loss = criterion(outputs, labels)\n",
        "            # 역전파 학습\n",
        "            loss.backward()\n",
        "            # 파라미터 업데이트\n",
        "            optimizer.step()\n",
        "\n",
        "            # 예측값 계산\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            # 손실 합산\n",
        "            runningLoss += loss.item() * inputs.size(0)\n",
        "            # 정확도 합산\n",
        "            runningCorrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # 반복 횟수 단위로 Train 평균 손실 및 정확도 계산\n",
        "        epochLoss = runningLoss / len(trainLoader.dataset)\n",
        "        epochAcc = runningCorrects.double() / len(trainLoader.dataset)\n",
        "        print(f\"Epoch {epoch+1}/{numEpochs} - Train Loss: {epochLoss:.4f} Acc: {epochAcc:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        # 모델을 평가 모드로 설정\n",
        "        model.eval()\n",
        "        valLoss = 0.0\n",
        "        valCorrects = 0\n",
        "\n",
        "        # 그래디언트 비활성화\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in valLoader:\n",
        "                # 이미지와 라벨(클래스)\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                # 모델 forward pass\n",
        "                outputs = model(inputs)\n",
        "                # 손실함수 계산 (출력, 정답)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # 예측값 계산\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                # 손실 합산\n",
        "                valLoss += loss.item() * inputs.size(0)\n",
        "                # 정확도 합산\n",
        "                valCorrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # 반복 횟수 단위로 Validation 평균 손실 및 정확도 계산\n",
        "        valLoss /= len(valLoader.dataset)\n",
        "        val_acc = valCorrects.double() / len(valLoader.dataset)\n",
        "        print(f\"Validation Loss: {valLoss:.4f} Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # Scheduler: Validation Loss 기반으로 학습률 조정\n",
        "        scheduler.step(valLoss)\n",
        "\n",
        "        # Early Stopping\n",
        "        # 개선이 되면\n",
        "        if valLoss < best_val_loss:\n",
        "            best_val_loss = valLoss\n",
        "            counter = 0\n",
        "            torch.save(model, best_model_path)\n",
        "            print(f\"Saved best model with Val Loss: {best_val_loss:.4f}\")\n",
        "        # 개선이 안되면\n",
        "        else:\n",
        "            counter += 1\n",
        "            print(f\"No improvement in {counter}/{patience} epochs\")\n",
        "            if counter >= patience:\n",
        "                print(\"Early stopping triggered in Stage 1\")\n",
        "                break\n",
        "\n",
        "    # Backbone 동결 해제 후 전체 모델 Fine-tuning\n",
        "    print(\"\\nStage 2: Fine-tuning entire model\")\n",
        "    # Backbone 동결 해제\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    # 옵티마이저의 학습률을 더 작게 설정\n",
        "    if use_l2:\n",
        "      optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-4)\n",
        "    else:\n",
        "      optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "    # 나머지 epoch 동안 학습 (내용은 동일)\n",
        "    for epoch in range(numEpochs//2, numEpochs):\n",
        "        # Train\n",
        "        model.train()\n",
        "        runningLoss = 0.0\n",
        "        runningCorrects = 0\n",
        "\n",
        "        for inputs, labels in trainLoader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            runningLoss += loss.item() * inputs.size(0)\n",
        "            runningCorrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epochLoss = runningLoss / len(trainLoader.dataset)\n",
        "        epochAcc = runningCorrects.double() / len(trainLoader.dataset)\n",
        "        print(f\"Epoch {epoch+1}/{numEpochs} - Train Loss: {epochLoss:.4f} Acc: {epochAcc:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        valLoss = 0.0\n",
        "        valCorrects = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in valLoader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                valLoss += loss.item() * inputs.size(0)\n",
        "                valCorrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        valLoss /= len(valLoader.dataset)\n",
        "        val_acc = valCorrects.double() / len(valLoader.dataset)\n",
        "        print(f\"Validation Loss: {valLoss:.4f} Acc: {val_acc:.4f}\")\n",
        "\n",
        "        scheduler.step(valLoss)\n",
        "\n",
        "        if valLoss < best_val_loss:\n",
        "            best_val_loss = valLoss\n",
        "            counter = 0\n",
        "            torch.save(model, best_model_path)\n",
        "            print(f\"Saved best model with Val Loss: {best_val_loss:.4f}\")\n",
        "        else:\n",
        "            counter += 1\n",
        "            print(f\"No improvement in {counter}/{patience} epochs\")\n",
        "            if counter >= patience:\n",
        "                print(\"Early stopping triggered in Stage 2\")\n",
        "                break\n",
        "\n",
        "    print(f\"Training completed. Best model saved at: {best_model_path}\")"
      ],
      "metadata": {
        "id": "5rGCZBvvEWRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def TestModel(model, testLoader):\n",
        "    all_preds = []\n",
        "    all_probs = []  # AUC 계산용 softmax 확률\n",
        "    all_labels = []\n",
        "\n",
        "    testCorrects = 0\n",
        "    testLoss = 0.0\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testLoader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # 예측 클래스\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            # softmax 확률 (클래스 1의 확률만)\n",
        "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
        "\n",
        "            testLoss += loss.item() * inputs.size(0)\n",
        "            testCorrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # 평균 계산\n",
        "    testLoss /= len(testLoader.dataset)\n",
        "    testAcc = testCorrects.double() / len(testLoader.dataset)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    precision = precision_score(all_labels, all_preds, average='macro')\n",
        "    recall = recall_score(all_labels, all_preds, average='macro')\n",
        "    auc = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "    print(f\"Test Accuracy  : {testAcc:.4f}\")\n",
        "    print(f\"Test Loss      : {testLoss:.4f}\")\n",
        "    print(f\"ROC-AUC        : {auc:.4f}\")\n",
        "    print(f\"Precision      : {precision:.4f}\")\n",
        "    print(f\"Recall         : {recall:.4f}\")\n",
        "    print(f\"F1-macro       : {f1:.4f}\")\n",
        "\n",
        "    return testAcc.item(), testLoss, auc, precision, recall, f1"
      ],
      "metadata": {
        "id": "NuuvedRxBo8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습 및 테스트"
      ],
      "metadata": {
        "id": "4rXgBKTrFQo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 불러오기\n",
        "model = create_model()\n",
        "\n",
        "# CrossEntropyLoss로 손실 함수 설정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Adam으로 옵티마이저로 사용 (filter를 통해 require_grad = True, 동결되지 않은 것만 업데이트)\n",
        "# weight_decay = 1e-4 : L2 정규화 적용으로 과적합 방지\n",
        "if use_l2:\n",
        "  optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, weight_decay=1e-4)\n",
        "else:\n",
        "  optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
        "# 합습률 스케줄러 설정\n",
        "# 검증 손실이 줄어들지 않으면 learning rate 줄임 (수렴 및 안정화)\n",
        "# min 모드 : 손실이 최소화되지 않으면 작동 / factor : 학습률을 x배 줄임 / patience : x번 학습동안 개선되지 않으면 발동 / verbose : 메시지 출력\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "# Train 모델 실행\n",
        "TrainModel(model, criterion, optimizer, scheduler, trainLoader, valLoader, numEpochs=20, patience=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3kfCDRhF6Zk",
        "outputId": "6748894e-bf96-4717-a5ba-4fbbf0d2d6f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stage 1: Training fc layer only (Backbone frozen)\n",
            "Epoch 1/20 - Train Loss: 0.3291 Acc: 0.8618\n",
            "Validation Loss: 0.3527 Acc: 0.9109\n",
            "Saved best model with Val Loss: 0.3527\n",
            "Epoch 2/20 - Train Loss: 0.2106 Acc: 0.9244\n",
            "Validation Loss: 0.1155 Acc: 0.9457\n",
            "Saved best model with Val Loss: 0.1155\n",
            "Epoch 3/20 - Train Loss: 0.1480 Acc: 0.9444\n",
            "Validation Loss: 0.2237 Acc: 0.9167\n",
            "No improvement in 1/5 epochs\n",
            "Epoch 4/20 - Train Loss: 0.1253 Acc: 0.9574\n",
            "Validation Loss: 0.1666 Acc: 0.9360\n",
            "No improvement in 2/5 epochs\n",
            "Epoch 5/20 - Train Loss: 0.1186 Acc: 0.9535\n",
            "Validation Loss: 0.0845 Acc: 0.9767\n",
            "Saved best model with Val Loss: 0.0845\n",
            "Epoch 6/20 - Train Loss: 0.0961 Acc: 0.9638\n",
            "Validation Loss: 0.0823 Acc: 0.9709\n",
            "Saved best model with Val Loss: 0.0823\n",
            "Epoch 7/20 - Train Loss: 0.0924 Acc: 0.9677\n",
            "Validation Loss: 0.0938 Acc: 0.9787\n",
            "No improvement in 1/5 epochs\n",
            "Epoch 8/20 - Train Loss: 0.0745 Acc: 0.9761\n",
            "Validation Loss: 0.1179 Acc: 0.9671\n",
            "No improvement in 2/5 epochs\n",
            "Epoch 9/20 - Train Loss: 0.0739 Acc: 0.9729\n",
            "Validation Loss: 0.1000 Acc: 0.9632\n",
            "No improvement in 3/5 epochs\n",
            "Epoch 10/20 - Train Loss: 0.1025 Acc: 0.9619\n",
            "Validation Loss: 0.0659 Acc: 0.9748\n",
            "Saved best model with Val Loss: 0.0659\n",
            "\n",
            "Stage 2: Fine-tuning entire model\n",
            "Epoch 11/20 - Train Loss: 0.0406 Acc: 0.9884\n",
            "Validation Loss: 0.0564 Acc: 0.9787\n",
            "Saved best model with Val Loss: 0.0564\n",
            "Epoch 12/20 - Train Loss: 0.0407 Acc: 0.9851\n",
            "Validation Loss: 0.0568 Acc: 0.9767\n",
            "No improvement in 1/5 epochs\n",
            "Epoch 13/20 - Train Loss: 0.0399 Acc: 0.9819\n",
            "Validation Loss: 0.0546 Acc: 0.9767\n",
            "Saved best model with Val Loss: 0.0546\n",
            "Epoch 14/20 - Train Loss: 0.0263 Acc: 0.9929\n",
            "Validation Loss: 0.0570 Acc: 0.9748\n",
            "No improvement in 1/5 epochs\n",
            "Epoch 15/20 - Train Loss: 0.0279 Acc: 0.9903\n",
            "Validation Loss: 0.0596 Acc: 0.9748\n",
            "No improvement in 2/5 epochs\n",
            "Epoch 16/20 - Train Loss: 0.0232 Acc: 0.9961\n",
            "Validation Loss: 0.0608 Acc: 0.9748\n",
            "No improvement in 3/5 epochs\n",
            "Epoch 17/20 - Train Loss: 0.0256 Acc: 0.9903\n",
            "Validation Loss: 0.0573 Acc: 0.9767\n",
            "No improvement in 4/5 epochs\n",
            "Epoch 18/20 - Train Loss: 0.0276 Acc: 0.9929\n",
            "Validation Loss: 0.0625 Acc: 0.9767\n",
            "No improvement in 5/5 epochs\n",
            "Early stopping triggered in Stage 2\n",
            "Training completed. Best model saved at: /content/drive/MyDrive/model/11110_best_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{use_background}{use_agumentation}{use_dropout}{use_freezing}{use_l2}_best_model.pth\")\n",
        "best_model_path = f\"/content/drive/MyDrive/model/{use_background}{use_agumentation}{use_dropout}{use_freezing}{use_l2}_best_model.pth\"\n",
        "model = torch.load(best_model_path, weights_only=False)\n",
        "model.to(device)\n",
        "\n",
        "# 테스트\n",
        "result = TestModel(model, testLoader)"
      ],
      "metadata": {
        "id": "BOgXSHwDF8G8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "245beccc-41cd-458e-cce6-8de0ca55ba58",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11110_best_model.pth\n",
            "Test Accuracy  : 0.9845\n",
            "Test Loss      : 0.0450\n",
            "ROC-AUC        : 0.9985\n",
            "Precision      : 0.9845\n",
            "Recall         : 0.9846\n",
            "F1-macro       : 0.9845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lICt0ucFQJvP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}