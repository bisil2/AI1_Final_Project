{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOp2SDzSbIxTOGML9h23Q9P"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 02) ì •ìƒ/ê°ì—¼ ì´ì§„ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ(Inception v4)"
      ],
      "metadata": {
        "id": "z1juJZgh_8Z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_background = 1\n",
        "use_agumentation = 1\n",
        "use_dropout = 1\n",
        "use_l2 = 1"
      ],
      "metadata": {
        "id": "70f-qo0wj-Gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° Import"
      ],
      "metadata": {
        "id": "j2f4Vu4gAM42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' íŒ¨í‚¤ì§€ ì„¤ì¹˜ '''\n",
        "!pip install torch torchvision\n",
        "\n",
        "# =============================\n",
        "# torch : ëª¨ë¸ ì‹¤í–‰, í•™ìŠµ, ì¶”ë¡ ì— í•„ìˆ˜ì ì¸ PyTorch í”„ë ˆì„ì›Œí¬\n",
        "# torchvision : ì´ë¯¸ì§€ ì²˜ë¦¬ ê´€ë ¨ ë„êµ¬ ì œê³µ\n",
        "# ============================="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3JaYUpQAP6e",
        "outputId": "eecde818-bbdb-407f-894c-1e92010d627e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Google Drive ì—°ë™'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "'''í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ import'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import zipfile\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwU4aNSCAR5Y",
        "outputId": "004efa80-df96-4fc3-cfd1-df1a82a40ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"
      ],
      "metadata": {
        "id": "pWHCwWFEAltP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Label ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°'''\n",
        "rawdata = pd.read_csv(\"/content/drive/MyDrive/data/rawdata.csv\")"
      ],
      "metadata": {
        "id": "HAzCnRGJApPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Image ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°'''\n",
        "if use_background:\n",
        "  zipName = 'data'\n",
        "else:\n",
        "  zipName = 'raw'\n",
        "\n",
        "# data í´ë” ìƒì„±\n",
        "targetPath = '/content/data/'\n",
        "os.makedirs(targetPath, exist_ok=True)\n",
        "\n",
        "# ì••ì¶• íŒŒì¼ contentë¡œ ë³µì‚¬ => contentì— ìˆìœ¼ë©´ ì²˜ë¦¬ì†ë„ê°€ ë¹„êµì  ë¹ ë¦„\n",
        "rootZip = f'/content/drive/MyDrive/data/{zipName}.zip'\n",
        "targetZip = f'/content/{zipName}.zip'\n",
        "shutil.copyfile(rootZip, targetZip)\n",
        "\n",
        "# zipfile.ZipFileë¡œ ì••ì¶• íŒŒì¼ì„ ì—´ê³ , ì••ì¶•ëœ ëª¨ë“  íŒŒì¼ì„ targetPathë¡œ ì´ë™(ì••ì¶• í•´ì œ)\n",
        "with zipfile.ZipFile(targetZip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(targetPath)"
      ],
      "metadata": {
        "id": "-I56jW4lAsiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ë°ì´í„° Split"
      ],
      "metadata": {
        "id": "H0AfAUzFAt3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Train:Val:Test = 6:2:2 ë¶„í• '''\n",
        "# rawdataë¥¼ ë¶„í• . train:(val+test) = 6:4\n",
        "train, temp = train_test_split(rawdata, test_size=0.4, random_state=1)\n",
        "\n",
        "# rawdataë¥¼ ë¶„í• . val:test = 5:5\n",
        "val, test = train_test_split(temp, test_size=0.5, random_state=1)"
      ],
      "metadata": {
        "id": "OmEJwNX7BAqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ë°ì´í„°ì…‹ í´ë˜ìŠ¤, Transform ìƒì„±"
      ],
      "metadata": {
        "id": "Wss5QZOvD17G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' DataSet í´ë˜ìŠ¤ ì •ì˜ '''\n",
        "# =============================\n",
        "# ëª©ì  : DataFrameì— ì €ì¥ëœ ì´ë¯¸ì§€ ê²½ë¡œì™€ ë¼ë²¨ ë“±ì„ ë¶ˆëŸ¬ì˜¤ê³ , ì „ì²˜ë¦¬ í›„ (image, label) ë¦¬í„´\n",
        "# ë§¤ê°œë³€ìˆ˜(?)\n",
        "#  - dataframe : ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„/í´ë˜ìŠ¤ ë“±ì´ í¬í•¨ëœ ë³€ìˆ˜\n",
        "#  - rootDir : ì´ë¯¸ì§€ë“¤ì´ ì €ì¥ëœ ê²½ë¡œ\n",
        "#  - transform : torchvision.transformsë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸(ì „ì²˜ë¦¬ ë¬¶ìŒ? ì •ë„ë¡œ ì´í•´í•˜ë©´ ë  ë“¯)\n",
        "# =============================\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, dataframe, rootDir, transform=None):\n",
        "    self.dataframe = dataframe\n",
        "    self.rootDir = rootDir\n",
        "    self.transform = transform\n",
        "\n",
        "  # ë°ì´í„°ì…‹ì˜ ì´ ìƒ˜í”Œ ìˆ˜ ë°˜í™˜\n",
        "  def __len__(self):\n",
        "    return len(self.dataframe)\n",
        "\n",
        "  # idxë²ˆì§¸ ë°ì´í„° ë¦¬í„´\n",
        "  def __getitem__(self, idx):\n",
        "    # DataFrameì˜ idxë²ˆì§¸ í–‰ì„ rowì— ì €ì¥\n",
        "    row = self.dataframe.iloc[idx]\n",
        "    # ì´ë¯¸ì§€ ê²½ë¡œ ë¶ˆëŸ¬ì˜¤ê¸°(row['image']ëŠ” íŒŒì¼ëª…ì´ë¯€ë¡œ, ìƒìœ„ ê²½ë¡œì™€ ë”í•´ì¤Œ; íŒŒì¼ ì´ë¦„ì´ '.JPG'ë¡œ ëœ ê²½ìš°ë„ ìˆì–´ì„œ í†µì¼)\n",
        "    imgName = os.path.join(self.rootDir, row['image'].replace('.JPG', '.jpg'))\n",
        "\n",
        "    # ì´ë¯¸ì§€ íŒŒì¼ì„ ì—´ê³ , RGBë¡œ ë³€í™˜\n",
        "    image = Image.open(imgName).convert('RGB')\n",
        "\n",
        "    # trasformì´ ì •ì˜ë˜ì–´ ìˆë‹¤ë©´, ì „ì²˜ë¦¬ ì ìš©\n",
        "    if self.transform:\n",
        "        image = self.transform(image)\n",
        "\n",
        "    # ë¼ë²¨ ì €ì¥\n",
        "    label = row['class']\n",
        "\n",
        "    # (ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€, ë¼ë²¨) ë¦¬í„´\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "VC_MaxdUD70V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Transform ì •ì˜'''\n",
        "# train, val, test ìš©ë„ì— ë”°ë¼ ì „ì²˜ë¦¬ë¥¼ ë‹¤ë¥´ê²Œ ì ìš©\n",
        "if use_agumentation:\n",
        "  transform = {\n",
        "      'train': transforms.Compose([\n",
        "          # ì´ë¯¸ì§€ë¥¼ 299x299ë¡œ í†µì¼ (Inception v4 ì…ë ¥ í¬ê¸°)\n",
        "          transforms.Resize((299, 299), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "          # í™•ë¥ ì ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ì¢Œìš° ë°˜ì „ (ë°ì´í„° ì¦ê°•)\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          # -15 ~ +15ë„ ì‚¬ì´ë¡œ ëœë¤ íšŒì „ (ë°ì´í„° ì¦ê°•)\n",
        "          transforms.RandomRotation(15),\n",
        "          # ë°ê¸°, ëŒ€ë¹„, ì±„ë„ ëœë¤ ì¡°ì ˆ (ë°ì´í„° ì¦ê°•)\n",
        "          transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "          # 10 % ë¹„ìœ¨ë¡œ ì¢Œìš° ë˜ëŠ” ìƒí™” ëœë¤ ì´ë™ (ë°ì´í„° ì¦ê°•)\n",
        "          transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "          # PIL ì´ë¯¸ì§€ë¥¼ Tensor í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (0~299 >> 0~1 ì‹¤ìˆ˜í˜•)\n",
        "          transforms.ToTensor(),\n",
        "          # í‰ê·  ë° í‘œì¤€í¸ì°¨ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™” (Image Netìœ¼ë¡œ ì‚¬ì „ í•™ìŠµë„ë‹ˆ ëª¨ë¸ê³¼ ì¼ì¹˜ì‹œí‚¤ê¸° ìœ„í•´)\n",
        "          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "      ]),\n",
        "      'val': transforms.Compose([\n",
        "          # ì´ë¯¸ì§€ë¥¼ 299x299ë¡œ í†µì¼ (Inception v4 ì…ë ¥ í¬ê¸°)\n",
        "          transforms.Resize((299, 299), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "          # PIL ì´ë¯¸ì§€ë¥¼ Tensor í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (0~299 >> 0~1 ì‹¤ìˆ˜í˜•)\n",
        "          transforms.ToTensor(),\n",
        "          # í‰ê·  ë° í‘œì¤€í¸ì°¨ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™” (Image Netìœ¼ë¡œì‚¬ì „ í•™ìŠµë„ë‹ˆ ëª¨ë¸ê³¼ ì¼ì¹˜ì‹œí‚¤ê¸° ìœ„í•´)\n",
        "          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "      ]),\n",
        "      'test': transforms.Compose([ # valê³¼ ë™ì¼/ trainê³¼ ë‹¬ë¦¬ í‰ê°€ ìš©ë„ê¸° ë•Œë¬¸ì— valê³¼ testì—ëŠ” ë°ì´í„° ì¦ê°•ì´ ì—†ìŒ.\n",
        "          transforms.Resize((299, 299), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "      ])\n",
        "  }\n",
        "else:\n",
        "  transform = {\n",
        "      'train': transforms.Compose([\n",
        "          # ì´ë¯¸ì§€ë¥¼ 299x299ë¡œ í†µì¼ (Inception v4 ì…ë ¥ í¬ê¸°)\n",
        "          transforms.Resize((299, 299), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "          # PIL ì´ë¯¸ì§€ë¥¼ Tensor í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (0~299 >> 0~1 ì‹¤ìˆ˜í˜•)\n",
        "          transforms.ToTensor(),\n",
        "          # í‰ê·  ë° í‘œì¤€í¸ì°¨ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™” (Image Netìœ¼ë¡œ ì‚¬ì „ í•™ìŠµë„ë‹ˆ ëª¨ë¸ê³¼ ì¼ì¹˜ì‹œí‚¤ê¸° ìœ„í•´)\n",
        "          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "      ]),\n",
        "      'val': transforms.Compose([\n",
        "          # ì´ë¯¸ì§€ë¥¼ 299x299ë¡œ í†µì¼ (Inception v4 ì…ë ¥ í¬ê¸°)\n",
        "          transforms.Resize((299, 299), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "          # PIL ì´ë¯¸ì§€ë¥¼ Tensor í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (0~299 >> 0~1 ì‹¤ìˆ˜í˜•)\n",
        "          transforms.ToTensor(),\n",
        "          # í‰ê·  ë° í‘œì¤€í¸ì°¨ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™” (Image Netìœ¼ë¡œì‚¬ì „ í•™ìŠµë„ë‹ˆ ëª¨ë¸ê³¼ ì¼ì¹˜ì‹œí‚¤ê¸° ìœ„í•´)\n",
        "          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "      ]),\n",
        "      'test': transforms.Compose([ # valê³¼ ë™ì¼/ trainê³¼ ë‹¬ë¦¬ í‰ê°€ ìš©ë„ê¸° ë•Œë¬¸ì— valê³¼ testì—ëŠ” ë°ì´í„° ì¦ê°•ì´ ì—†ìŒ.\n",
        "          transforms.Resize((299, 299), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "      ])\n",
        "  }"
      ],
      "metadata": {
        "id": "CK15qzZgCqQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "trainDataset = CustomDataset(train, '/content/data', transform=transform['train'])\n",
        "valDataset = CustomDataset(val, '/content/data', transform=transform['val'])\n",
        "testDataset = CustomDataset(test, '/content/data', transform=transform['test'])\n",
        "\n",
        "# DataLoader ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "trainLoader = DataLoader(trainDataset, batch_size=32, shuffle=False)\n",
        "valLoader = DataLoader(valDataset, batch_size=32, shuffle=False)\n",
        "testLoader = DataLoader(testDataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "463sGLomlNym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## í•™ìŠµ, í…ŒìŠ¤íŠ¸ ë©”ì†Œë“œ ì •ì˜"
      ],
      "metadata": {
        "id": "P1VaSpJ4EMW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Inception-V4 ëª¨ë¸ ìƒì„± ë° ì •ì˜ '''\n",
        "\n",
        "# ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ì„¤ì • : GPU(cuda)ê°€ ê°€ëŠ¥í•˜ë©´ GPU, ì•„ë‹ˆë©´ CPU ì‚¬ìš©\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# =============================\n",
        "# ëª©ì  : ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê³  ì¬ì •ì˜\n",
        "# =============================\n",
        "def create_model():\n",
        "    # í•™ìŠµëª©ì ìœ¼ë¡œ Inception v4ëª¨ë¸ì„ ì§ì ‘ ë§Œë“¤ê±°ì„\n",
        "    # íƒ€ ëª¨ë¸ê³¼ ì°¨ì´ì : ì—¬ëŸ¬ í¬ê¸°ì˜ í•„í„°ë¥¼ ë³‘ë ¬ë¡œ ì‚¬ìš©í•¨ -> ë‹¤ì–‘í•œ ê´€ì ?ì—ì„œ íŠ¹ì§• ì¶”ì¶œ ê°€ëŠ¥í•¨\n",
        "\n",
        "    # êµ¬ì¡°: Input -> STEM -> Inception-A -> Reduction-A -> I-B -> R-B -> I-C -> Global Average Pooling -> Dropout -> FC -> Softmax\n",
        "\n",
        "    # Stem: ëª¨ë¸ì˜ ì²« ë¶€ë¶„ìœ¼ë¡œ, Inputì„ ë°›ì•„ íŠ¹ì§• ì¶”ì¶œ ë° ì°¨ì› ì¶•ì†Œ ì—­í• \n",
        "    # Inception: ë‹¤ì–‘í•œ í•„í„°ë¥¼ ë³‘ë ¬ë¡œ ì‚¬ìš©í•´ íŠ¹ì§• ì¶”ì¶œ. ë’· ë¬¸ìê°€ ì»¤ì§ˆìˆ˜ë¡ ê³ ìˆ˜ì¤€ì˜ íŠ¹ì§• ì¶”ì¶œ(ë³µì¡í•œ íŒ¨í„´)\n",
        "    # Reduction: ì´ë¯¸ì§€ í•´ìƒë„ ì¤„ì„(ë‹¤ìš´ìƒ˜í”Œë§). ë‹¤ìŒ ë¸”ë¡ì„ ìœ„í•œ ì—°ê²° ë‹¤ë¦¬ ì—­í• \n",
        "    # Global Average Pooling: ë§ˆì§€ë§‰ ì „ì²´ íŠ¹ì§•ì„ ì••ì¶•í•´ 1ì°¨ì› ë²¡í„°ë¡œ ë§Œë“¬\n",
        "    # Dropout: ê³¼ì í•© ë°©ì§€\n",
        "    # FC: ìµœì¢… ë¶„ë¥˜ ì¶œë ¥\n",
        "\n",
        "    # Stemì˜ ì¶œë ¥ì€ í•­ìƒ 35x35ì„.\n",
        "    class Stem(nn.Module):\n",
        "      def __init__(self):\n",
        "          super(Stem, self).__init__()\n",
        "          self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2)  # 149x149\n",
        "          self.conv2 = nn.Conv2d(32, 32, kernel_size=3)           # 147x147\n",
        "          self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 147x147\n",
        "\n",
        "          self.branch1 = nn.MaxPool2d(kernel_size=3, stride=2)    # 73x73\n",
        "          self.branch2 = nn.Conv2d(64, 96, kernel_size=3, stride=2)  # 73x73\n",
        "\n",
        "          self.branch3a = nn.Sequential(\n",
        "              nn.Conv2d(160, 64, kernel_size=1),\n",
        "              nn.Conv2d(64, 96, kernel_size=3)\n",
        "          )\n",
        "\n",
        "          self.branch3b = nn.Sequential(\n",
        "              nn.Conv2d(160, 64, kernel_size=1),\n",
        "              nn.Conv2d(64, 64, kernel_size=(7, 1), padding=(3, 0)),\n",
        "              nn.Conv2d(64, 64, kernel_size=(1, 7), padding=(0, 3)),\n",
        "              nn.Conv2d(64, 96, kernel_size=3)\n",
        "          )\n",
        "\n",
        "          self.branch4a = nn.Conv2d(192, 192, kernel_size=3, stride=2)\n",
        "          self.branch4b = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "      def forward(self, x):\n",
        "          x = self.conv1(x)\n",
        "          x = self.conv2(x)\n",
        "          x = self.conv3(x)\n",
        "          x1 = self.branch1(x)\n",
        "          x2 = self.branch2(x)\n",
        "          x = torch.cat([x1, x2], 1)\n",
        "\n",
        "          x1 = self.branch3a(x)\n",
        "          x2 = self.branch3b(x)\n",
        "          x = torch.cat([x1, x2], 1)\n",
        "\n",
        "          x1 = self.branch4a(x)\n",
        "          x2 = self.branch4b(x)\n",
        "          x = torch.cat([x1, x2], 1)\n",
        "          return x\n",
        "\n",
        "\n",
        "    # InceptionAì˜ ì¶œë ¥ ì±„ë„ ìˆ˜ëŠ” í•­ìƒ 384ì„.\n",
        "    class InceptionA(nn.Module):\n",
        "      def __init__(self, in_channels):\n",
        "        super(InceptionA, self).__init__()\n",
        "\n",
        "        # 1x1 Conv\n",
        "        self.branch1 = nn.Conv2d(in_channels, 96, kernel_size=1)\n",
        "\n",
        "        # 1x1 Conv -> 3x3 Conv\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=1),\n",
        "            nn.Conv2d(64, 96, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        # 1x1 Conv -> 3x3 Conv -> 3x3 Conv\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=1),\n",
        "            nn.Conv2d(64, 96, kernel_size=3, padding=1),\n",
        "            nn.Conv2d(96, 96, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        # Average Pooling -> 1x1 Conv\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_channels, 96, kernel_size=1)\n",
        "        )\n",
        "      def forward(self, x):\n",
        "        b1 = self.branch1(x)\n",
        "        b2 = self.branch2(x)\n",
        "        b3 = self.branch3(x)\n",
        "        b4 = self.branch4(x)\n",
        "        # ì±„ë„ ë°©í–¥ìœ¼ë¡œ í•©ì¹˜ê¸°\n",
        "        out = torch.cat([b1, b2, b3, b4], dim=1)\n",
        "        return out\n",
        "\n",
        "    class ReductionA(nn.Module):\n",
        "      def __init__(self, in_channels):\n",
        "        super(ReductionA, self).__init__()\n",
        "\n",
        "        self.branch1 = nn.Conv2d(in_channels, 384, kernel_size=3, stride=2)\n",
        "\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 192, kernel_size=1),\n",
        "            nn.Conv2d(192, 224, kernel_size=3, padding=1),\n",
        "            nn.Conv2d(224, 256, kernel_size=3, stride=2)\n",
        "        )\n",
        "\n",
        "        self.branch3 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "      def forward(self, x):\n",
        "        b1 = self.branch1(x)\n",
        "        b2 = self.branch2(x)\n",
        "        b3 = self.branch3(x)\n",
        "        out = torch.cat([b1, b2, b3], dim=1)\n",
        "        return out\n",
        "\n",
        "    class InceptionB(nn.Module):\n",
        "      def __init__(self, in_channels):\n",
        "        super(InceptionB, self).__init__()\n",
        "\n",
        "        self.branch1 = nn.Conv2d(in_channels, 384, kernel_size=1)\n",
        "\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 192, kernel_size=1),\n",
        "            nn.Conv2d(192, 224, kernel_size=(1, 7), padding=(0, 3)),\n",
        "            nn.Conv2d(224, 256, kernel_size=(7, 1), padding=(3, 0))\n",
        "        )\n",
        "\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 192, kernel_size=1),\n",
        "            nn.Conv2d(192, 192, kernel_size=(7, 1), padding=(3, 0)),\n",
        "            nn.Conv2d(192, 224, kernel_size=(1, 7), padding=(0, 3)),\n",
        "            nn.Conv2d(224, 224, kernel_size=(7, 1), padding=(3, 0)),\n",
        "            nn.Conv2d(224, 256, kernel_size=(1, 7), padding=(0, 3))\n",
        "        )\n",
        "\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_channels, 128, kernel_size=1)\n",
        "        )\n",
        "\n",
        "      def forward(self, x):\n",
        "        b1 = self.branch1(x)\n",
        "        b2 = self.branch2(x)\n",
        "        b3 = self.branch3(x)\n",
        "        b4 = self.branch4(x)\n",
        "        out = torch.cat([b1, b2, b3, b4], dim=1)\n",
        "        return out\n",
        "\n",
        "    class ReductionB(nn.Module):\n",
        "      def __init__(self, in_channels):\n",
        "        super(ReductionB, self).__init__()\n",
        "\n",
        "        self.branch1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 192, kernel_size=1),\n",
        "            nn.Conv2d(192, 192, kernel_size=3, stride=2)\n",
        "        )\n",
        "\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 256, kernel_size=1),\n",
        "            nn.Conv2d(256, 256, kernel_size=(1, 7), padding=(0, 3)),\n",
        "            nn.Conv2d(256, 320, kernel_size=(7, 1), padding=(3, 0)),\n",
        "            nn.Conv2d(320, 320, kernel_size=3, stride=2)\n",
        "        )\n",
        "\n",
        "        self.branch3 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "      def forward(self, x):\n",
        "        b1 = self.branch1(x)\n",
        "        b2 = self.branch2(x)\n",
        "        b3 = self.branch3(x)\n",
        "        out = torch.cat([b1, b2, b3], dim=1)\n",
        "        return out\n",
        "\n",
        "    class InceptionC(nn.Module):\n",
        "      def __init__(self, in_channels):\n",
        "        super(InceptionC, self).__init__()\n",
        "\n",
        "        self.branch1 = nn.Conv2d(in_channels, 256, kernel_size=1)\n",
        "\n",
        "        self.branch2_1 = nn.Conv2d(in_channels, 384, kernel_size=1)\n",
        "        self.branch2_2 = nn.Conv2d(384, 256, kernel_size=(1, 3), padding=(0, 1))\n",
        "        self.branch2_3 = nn.Conv2d(384, 256, kernel_size=(3, 1), padding=(1, 0))\n",
        "\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 384, kernel_size=1),\n",
        "            nn.Conv2d(384, 448, kernel_size=3, padding=1),\n",
        "            nn.Conv2d(448, 512, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        self.branch3_2a = nn.Conv2d(512, 256, kernel_size=(1, 3), padding=(0, 1))\n",
        "        self.branch3_2b = nn.Conv2d(512, 256, kernel_size=(3, 1), padding=(1, 0))\n",
        "\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_channels, 256, kernel_size=1)\n",
        "        )\n",
        "\n",
        "      def forward(self, x):\n",
        "        b1 = self.branch1(x)\n",
        "\n",
        "        b2 = self.branch2_1(x)\n",
        "        b2a = self.branch2_2(b2)\n",
        "        b2b = self.branch2_3(b2)\n",
        "        b2 = torch.cat([b2a, b2b], dim=1)\n",
        "\n",
        "        b3 = self.branch3(x)\n",
        "        b3a = self.branch3_2a(b3)\n",
        "        b3b = self.branch3_2b(b3)\n",
        "        b3 = torch.cat([b3a, b3b], dim=1)\n",
        "\n",
        "        b4 = self.branch4(x)\n",
        "\n",
        "        out = torch.cat([b1, b2, b3, b4], dim=1)\n",
        "        return out\n",
        "\n",
        "    class InceptionV4(nn.Module):\n",
        "      def __init__(self, num_classes=2):\n",
        "        super(InceptionV4, self).__init__()\n",
        "\n",
        "        self.stem = Stem()\n",
        "\n",
        "        self.InceptionA = nn.Sequential(\n",
        "            InceptionA(384),\n",
        "            InceptionA(384),\n",
        "            InceptionA(384),\n",
        "            InceptionA(384)\n",
        "        )\n",
        "\n",
        "        self.reductionA = ReductionA(384)\n",
        "\n",
        "        self.InceptionB = nn.Sequential(\n",
        "            InceptionB(1024),\n",
        "            InceptionB(1024),\n",
        "            InceptionB(1024),\n",
        "            InceptionB(1024),\n",
        "            InceptionB(1024),\n",
        "            InceptionB(1024),\n",
        "            InceptionB(1024),\n",
        "        )\n",
        "\n",
        "        self.reductionB = ReductionB(1024)\n",
        "\n",
        "        self.InceptionC = nn.Sequential(\n",
        "            InceptionC(1536),\n",
        "            InceptionC(1536),\n",
        "            InceptionC(1536)\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        if use_dropout:\n",
        "          self.head_drop = nn.Dropout(p=0.2)\n",
        "          self.classif = nn.Sequential(\n",
        "              nn.Linear(1536, 256),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(0.2),\n",
        "              nn.Linear(256, num_classes),\n",
        "          )\n",
        "        else:\n",
        "          self.head_drop = nn.Dropout(p=0.0)\n",
        "          self.classif = nn.Sequential(\n",
        "              nn.Linear(1536, 256),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(256, num_classes),\n",
        "          )\n",
        "\n",
        "      def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.InceptionA(x)\n",
        "        x = self.reductionA(x)\n",
        "        x = self.InceptionB(x)\n",
        "        x = self.reductionB(x)\n",
        "        x = self.InceptionC(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.head_drop(x)\n",
        "        x = self.classif(x)\n",
        "        return x\n",
        "\n",
        "    return InceptionV4().to(device)\n",
        "\n",
        "# ëª¨ë¸ ì €ì¥ ì‹œì—ëŠ” ë‹¤ìŒì²˜ëŸ¼ state_dictë§Œ ì €ì¥í•˜ì„¸ìš”:\n",
        "# torch.save(model.state_dict(), path)\n",
        "\n",
        "# ëª¨ë¸ ë¡œë”© ì‹œì—ëŠ” ë‹¤ìŒì²˜ëŸ¼ ì‚¬ìš©í•˜ì„¸ìš”:\n",
        "# model = create_model()\n",
        "# model.load_state_dict(torch.load(path))\n",
        "# model.eval()\n"
      ],
      "metadata": {
        "id": "C3zC1ZxPo_QH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' í•™ìŠµ ëª¨ë¸ '''\n",
        "# =============================\n",
        "# ëª©ì  : ëª¨ë¸ í•™ìŠµ\n",
        "# Early Stopping : val lossê°€ 5ë²ˆ ì´ìƒ ê°œì„ ì´ ì•ˆë  ê²½ìš°, ì¢…ë£Œ\n",
        "# =============================\n",
        "def TrainModel(model, criterion, optimizer, scheduler, trainLoader, valLoader, numEpochs=20, patience=5):\n",
        "    # Early Stopping ê´€ë ¨ ë³€ìˆ˜\n",
        "    # loss ê¸°ì¤€ê°’ì„ ìµœëŒ“ê°’ìœ¼ë¡œ ì„¤ì •\n",
        "    best_val_loss = float('inf')\n",
        "    # early stopping counter 0ìœ¼ë¡œ ì„¤ì •\n",
        "    counter = 0\n",
        "    # best model ì €ì¥ ê²½ë¡œ ì„¤ì •\n",
        "    best_model_path = f\"/content/drive/MyDrive/model/Inception v4 ì´ˆê¸°á„’á…¡á†¨á„‰á…³á†¸/{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model.pth\"\n",
        "\n",
        "    # Backbone ë™ê²° ìƒíƒœì—ì„œ fc layerë§Œ í•™ìŠµ\n",
        "    for epoch in range(numEpochs):\n",
        "        # Train\n",
        "        # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •\n",
        "        model.train()\n",
        "        runningLoss = 0.0\n",
        "        runningCorrects = 0\n",
        "\n",
        "        # í›ˆë ¨ ë°ì´í„° ë°˜ë³µ í•™ìŠµ\n",
        "        for inputs, labels in trainLoader:\n",
        "            # ì´ë¯¸ì§€ì™€ ë¼ë²¨(í´ë˜ìŠ¤)\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # ê¸°ì¡´ ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™”\n",
        "            optimizer.zero_grad()\n",
        "            # ëª¨ë¸ forward pass\n",
        "            outputs = model(inputs)\n",
        "            # ì†ì‹¤í•¨ìˆ˜ ê³„ì‚° (ì¶œë ¥, ì •ë‹µ)\n",
        "            loss = criterion(outputs, labels)\n",
        "            # ì—­ì „íŒŒ í•™ìŠµ\n",
        "            loss.backward()\n",
        "            # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸\n",
        "            optimizer.step()\n",
        "\n",
        "            # ì˜ˆì¸¡ê°’ ê³„ì‚°\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            # ì†ì‹¤ í•©ì‚°\n",
        "            runningLoss += loss.item() * inputs.size(0)\n",
        "            # ì •í™•ë„ í•©ì‚°\n",
        "            runningCorrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # ë°˜ë³µ íšŸìˆ˜ ë‹¨ìœ„ë¡œ Train í‰ê·  ì†ì‹¤ ë° ì •í™•ë„ ê³„ì‚°\n",
        "        epochLoss = runningLoss / len(trainLoader.dataset)\n",
        "        epochAcc = runningCorrects.double() / len(trainLoader.dataset)\n",
        "        print(f\"Epoch {epoch+1}/{numEpochs} - Train Loss: {epochLoss:.4f} Acc: {epochAcc:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
        "        model.eval()\n",
        "        valLoss = 0.0\n",
        "        valCorrects = 0\n",
        "\n",
        "        # ê·¸ë˜ë””ì–¸íŠ¸ ë¹„í™œì„±í™”\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in valLoader:\n",
        "                # ì´ë¯¸ì§€ì™€ ë¼ë²¨(í´ë˜ìŠ¤)\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                # ëª¨ë¸ forward pass\n",
        "                outputs = model(inputs)\n",
        "                # ì†ì‹¤í•¨ìˆ˜ ê³„ì‚° (ì¶œë ¥, ì •ë‹µ)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # ì˜ˆì¸¡ê°’ ê³„ì‚°\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                # ì†ì‹¤ í•©ì‚°\n",
        "                valLoss += loss.item() * inputs.size(0)\n",
        "                # ì •í™•ë„ í•©ì‚°\n",
        "                valCorrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # ë°˜ë³µ íšŸìˆ˜ ë‹¨ìœ„ë¡œ Validation í‰ê·  ì†ì‹¤ ë° ì •í™•ë„ ê³„ì‚°\n",
        "        valLoss /= len(valLoader.dataset)\n",
        "        val_acc = valCorrects.double() / len(valLoader.dataset)\n",
        "        print(f\"Validation Loss: {valLoss:.4f} Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # Scheduler: Validation Loss ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµë¥  ì¡°ì •\n",
        "        scheduler.step(valLoss)\n",
        "\n",
        "        # Early Stopping\n",
        "        # ê°œì„ ì´ ë˜ë©´\n",
        "        if valLoss < best_val_loss:\n",
        "            best_val_loss = valLoss\n",
        "            counter = 0\n",
        "            torch.save(model, best_model_path)\n",
        "            print(f\"Renewal best model: {best_val_loss:.4f}\")\n",
        "        # ê°œì„ ì´ ì•ˆë˜ë©´\n",
        "        else:\n",
        "            counter += 1\n",
        "            print(f\"No improvement in {counter}/{patience} epochs\")\n",
        "            if counter >= patience:\n",
        "                break"
      ],
      "metadata": {
        "id": "JEmAA8AGj-IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def TestModel(model, testLoader):\n",
        "    all_preds = []\n",
        "    all_probs = []  # AUC ê³„ì‚°ìš© softmax í™•ë¥ \n",
        "    all_labels = []\n",
        "\n",
        "    testCorrects = 0\n",
        "    testLoss = 0.0\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testLoader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # ì˜ˆì¸¡ í´ë˜ìŠ¤\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            # softmax í™•ë¥  (í´ë˜ìŠ¤ 1ì˜ í™•ë¥ ë§Œ)\n",
        "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
        "\n",
        "            testLoss += loss.item() * inputs.size(0)\n",
        "            testCorrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # í‰ê·  ê³„ì‚°\n",
        "    testLoss /= len(testLoader.dataset)\n",
        "    testAcc = testCorrects.double() / len(testLoader.dataset)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    precision = precision_score(all_labels, all_preds, average='macro')\n",
        "    recall = recall_score(all_labels, all_preds, average='macro')\n",
        "    auc = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "    print(f\"Test Accuracy  : {testAcc:.4f}\")\n",
        "    print(f\"Test Loss      : {testLoss:.4f}\")\n",
        "    print(f\"ROC-AUC        : {auc:.4f}\")\n",
        "    print(f\"Precision      : {precision:.4f}\")\n",
        "    print(f\"Recall         : {recall:.4f}\")\n",
        "    print(f\"F1-macro       : {f1:.4f}\")\n",
        "\n",
        "    return testAcc.item(), testLoss, auc, precision, recall, f1"
      ],
      "metadata": {
        "id": "NuuvedRxBo8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(model):\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            nn.init.constant_(m.weight, 1)\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            if 'classif' in name:\n",
        "                nn.init.normal_(m.weight, mean=0.0, std=0.5)  # ğŸ’¥ í­ë„“ê²Œ\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0.2)\n",
        "            else:\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0.1)"
      ],
      "metadata": {
        "id": "EVAwlnmwmGiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "x = torch.randn(4, 3, 299, 299).to(device)\n",
        "y = model(x)\n",
        "print(\"FC output shape:\", y.shape)\n",
        "print(\"Logits mean/std:\", y.mean().item(), y.std().item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "858cHaOqBlJS",
        "outputId": "160ec2e0-3f49-4d42-ed63-8ea3f073fa11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FC output shape: torch.Size([4, 2])\n",
            "Logits mean/std: 0.019397489726543427 0.035522330552339554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "def init_weights_he(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.zeros_(m.bias)"
      ],
      "metadata": {
        "id": "x3xJc7uqYCGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ëª¨ë¸ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸"
      ],
      "metadata": {
        "id": "4rXgBKTrFQo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,2):\n",
        "  # ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "  model = create_model()\n",
        "  model.apply(init_weights_he)\n",
        "\n",
        "  # CrossEntropyLossë¡œ ì†ì‹¤ í•¨ìˆ˜ ì„¤ì •\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  # Adamìœ¼ë¡œ ì˜µí‹°ë§ˆì´ì €ë¡œ ì‚¬ìš© (filterë¥¼ í†µí•´ require_grad = True, ë™ê²°ë˜ì§€ ì•Šì€ ê²ƒë§Œ ì—…ë°ì´íŠ¸)\n",
        "  # weight_decay = 1e-4 : L2 ì •ê·œí™” ì ìš©ìœ¼ë¡œ ê³¼ì í•© ë°©ì§€\n",
        "  if use_l2:\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "  else:\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "  # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •\n",
        "  # ê²€ì¦ ì†ì‹¤ì´ ì¤„ì–´ë“¤ì§€ ì•Šìœ¼ë©´ learning rate ì¤„ì„ (ìˆ˜ë ´ ë° ì•ˆì •í™”)\n",
        "  # min ëª¨ë“œ : ì†ì‹¤ì´ ìµœì†Œí™”ë˜ì§€ ì•Šìœ¼ë©´ ì‘ë™ / factor : í•™ìŠµë¥ ì„ xë°° ì¤„ì„ / patience : xë²ˆ í•™ìŠµë™ì•ˆ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ ë°œë™ / verbose : ë©”ì‹œì§€ ì¶œë ¥\n",
        "  scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "  # Train ëª¨ë¸ ì‹¤í–‰\n",
        "  TrainModel(model, criterion, optimizer, scheduler, trainLoader, valLoader, numEpochs=20, patience=5)\n",
        "\n",
        "  os.rename(f\"/content/drive/MyDrive/model/Inception v4 ì´ˆê¸°á„’á…¡á†¨á„‰á…³á†¸/{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model.pth\", f\"/content/drive/MyDrive/model/Inception v4 ì´ˆê¸°á„’á…¡á†¨á„‰á…³á†¸/{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model_{i+1}.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "Ko7sT-B2d9KT",
        "outputId": "752cd552-a594-4d4d-e6a1-c02b0fc00fab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - Train Loss: 18758691966393.8828 Acc: 0.5207\n",
            "Validation Loss: 412088465931.9070 Acc: 0.6492\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "Can't pickle local object 'create_model.<locals>.InceptionV4'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-a5e066fd85e0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;31m# Train ëª¨ë¸ ì‹¤í–‰\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mTrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/content/drive/MyDrive/model/Inception v4 ì´ˆê¸°á„’á…¡á†¨á„‰á…³á†¸/{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model.pth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"/content/drive/MyDrive/model/Inception v4 ì´ˆê¸°á„’á…¡á†¨á„‰á…³á†¸/{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model_{i+1}.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-89650c90217c>\u001b[0m in \u001b[0;36mTrainModel\u001b[0;34m(model, criterion, optimizer, scheduler, trainLoader, valLoader, numEpochs, patience)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mbest_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Renewal best model: {best_val_loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# ê°œì„ ì´ ì•ˆë˜ë©´\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m             _save(\n\u001b[0m\u001b[1;32m    945\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                 \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyTorchPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m     \u001b[0mdata_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'create_model.<locals>.InceptionV4'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model.pth\")\n",
        "for i in range(2):\n",
        "  best_model_path = f\"/content/drive/MyDrive/model/Inception v4 ì´ˆê¸°á„’á…¡á†¨á„‰á…³á†¸/{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model_{i+1}.pth\"\n",
        "  model = torch.load(best_model_path, weights_only=False)\n",
        "  model.to(device)\n",
        "\n",
        "  # í…ŒìŠ¤íŠ¸\n",
        "  result = TestModel(model, testLoader)\n",
        "  print()"
      ],
      "metadata": {
        "id": "Zov9aTHBePqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "êµ¬ë²„ì „"
      ],
      "metadata": {
        "id": "aTayF3Amo1V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' í•™ìŠµ ëª¨ë¸ '''\n",
        "# =============================\n",
        "# ëª©ì  : ëª¨ë¸ í•™ìŠµ\n",
        "# ë‹¨ì¼ ë‹¨ê³„ í•™ìŠµ (Inception v4: ì‚¬ì „í•™ìŠµ X)\n",
        "# Early Stopping : val lossê°€ 6ë²ˆ ì´ìƒ ê°œì„ ì´ ì•ˆë  ê²½ìš°, ì¢…ë£Œ\n",
        "# =============================\n",
        "def TrainModel(model, criterion, optimizer, scheduler, trainLoader, valLoader, numEpochs=12, patience=6):\n",
        "    # Early Stopping ê´€ë ¨ ë³€ìˆ˜\n",
        "    best_val_loss = float('inf')\n",
        "    counter = 0\n",
        "    best_model_path = f\"/content/drive/MyDrive/model/Inception v4 ì´ˆê¸°á„’á…¡á†¨á„‰á…³á†¸/{use_background}{use_agumentation}{use_dropout}{use_l2}_best_model.pth\"\n",
        "\n",
        "    for epoch in range(numEpochs):\n",
        "        # Train\n",
        "        model.train()\n",
        "        runningLoss = 0.0\n",
        "        runningCorrects = 0\n",
        "\n",
        "        for inputs, labels in trainLoader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            runningLoss += loss.item() * inputs.size(0)\n",
        "            runningCorrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epochLoss = runningLoss / len(trainLoader.dataset)\n",
        "        epochAcc = runningCorrects.double() / len(trainLoader.dataset)\n",
        "        print(f\"Epoch {epoch+1}/{numEpochs} - Train Loss: {epochLoss:.4f} Acc: {epochAcc:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        valLoss = 0.0\n",
        "        valCorrects = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in valLoader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                valLoss += loss.item() * inputs.size(0)\n",
        "                valCorrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        valLoss /= len(valLoader.dataset)\n",
        "        val_acc = valCorrects.double() / len(valLoader.dataset)\n",
        "        print(f\"Validation Loss: {valLoss:.4f} Acc: {val_acc:.4f}\")\n",
        "\n",
        "        #scheduler.step(valLoss) # í™•ì¸ í•„ìš”\n",
        "        scheduler.step()\n",
        "        if valLoss < best_val_loss:\n",
        "            best_val_loss = valLoss\n",
        "            counter = 0\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            print(f\"Renewal best model: {best_val_loss:.4f}\")\n",
        "        else:\n",
        "            counter += 1\n",
        "            print(f\"No improvement in {counter}/{patience} epochs\")\n",
        "            if counter >= patience:\n",
        "                break"
      ],
      "metadata": {
        "id": "gX4Y44G431vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "model = create_model()\n",
        "\n",
        "# ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” ì ìš©\n",
        "initialize_weights(model)\n",
        "print(type(model.stem.conv1.weight))  # Parameter\n",
        "print(model.stem.conv1.weight.mean(), model.stem.conv1.weight.std())\n",
        "\n",
        "# ì†ì‹¤ í•¨ìˆ˜ ì •ì˜\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ì˜µí‹°ë§ˆì´ì € ì„¤ì • (í”„ë¦¬ì§• ì—†ìŒ â†’ ì „ì²´ íŒŒë¼ë¯¸í„° ì‚¬ìš©)\n",
        "if use_l2:\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4) # lr => 0.001?\n",
        "else:\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Cosine Annealing ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • (warm-up ì—†ì´ ë‹¨ì¼ ë‹¨ê³„) # í™•ì¸ í•„ìš” ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ í•´ì•¼í•˜ì§€ ì•Šì„ê¹Œ...!\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optimizer,\n",
        "    T_max=20,\n",
        "    eta_min=1e-6\n",
        ")\n",
        "\n",
        "# ëª¨ë¸ í•™ìŠµ ì‹¤í–‰\n",
        "TrainModel(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    trainLoader=trainLoader,\n",
        "    valLoader=valLoader,\n",
        "    numEpochs=20,\n",
        "    patience=5\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHcfTFM9aKQY",
        "outputId": "fa87c58c-cd7f-416a-aba7-cfe9ead84808",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.nn.parameter.Parameter'>\n",
            "tensor(1.6994e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0798, device='cuda:0', grad_fn=<StdBackward0>)\n",
            "Training full model (no freezing, since pretrained weights are not used)\n",
            "Epoch 1/20 - Train Loss: 11.6860 Acc: 0.5956\n",
            "Validation Loss: 0.6984 Acc: 0.6667\n",
            "Saved best model with Val Loss: 0.6984\n",
            "Epoch 2/20 - Train Loss: 0.6851 Acc: 0.6680\n",
            "Validation Loss: 0.7240 Acc: 0.6531\n",
            "No improvement in 1/5 epochs\n",
            "Epoch 3/20 - Train Loss: 0.6393 Acc: 0.6673\n",
            "Validation Loss: 0.6054 Acc: 0.7074\n",
            "Saved best model with Val Loss: 0.6054\n",
            "Epoch 4/20 - Train Loss: 0.6132 Acc: 0.6970\n",
            "Validation Loss: 0.6467 Acc: 0.6938\n",
            "No improvement in 1/5 epochs\n",
            "Epoch 5/20 - Train Loss: 0.5894 Acc: 0.6932\n",
            "Validation Loss: 0.5805 Acc: 0.7267\n",
            "Saved best model with Val Loss: 0.5805\n",
            "Epoch 6/20 - Train Loss: 0.6000 Acc: 0.6990\n",
            "Validation Loss: 0.5881 Acc: 0.7035\n",
            "No improvement in 1/5 epochs\n",
            "Epoch 7/20 - Train Loss: 0.5624 Acc: 0.7151\n",
            "Validation Loss: 0.5844 Acc: 0.7093\n",
            "No improvement in 2/5 epochs\n",
            "Epoch 8/20 - Train Loss: 0.5859 Acc: 0.7164\n",
            "Validation Loss: 0.5905 Acc: 0.7151\n",
            "No improvement in 3/5 epochs\n",
            "Epoch 9/20 - Train Loss: 0.5608 Acc: 0.7235\n",
            "Validation Loss: 0.6014 Acc: 0.7306\n",
            "No improvement in 4/5 epochs\n",
            "Epoch 10/20 - Train Loss: 0.5533 Acc: 0.7293\n",
            "Validation Loss: 0.5205 Acc: 0.7442\n",
            "Saved best model with Val Loss: 0.5205\n",
            "Epoch 11/20 - Train Loss: 0.5248 Acc: 0.7435\n",
            "Validation Loss: 0.4847 Acc: 0.7752\n",
            "Saved best model with Val Loss: 0.4847\n",
            "Epoch 12/20 - Train Loss: 0.5378 Acc: 0.7339\n",
            "Validation Loss: 0.4885 Acc: 0.7694\n",
            "No improvement in 1/5 epochs\n",
            "Epoch 13/20 - Train Loss: 0.5116 Acc: 0.7545\n",
            "Validation Loss: 0.4742 Acc: 0.7771\n",
            "Saved best model with Val Loss: 0.4742\n",
            "Epoch 14/20 - Train Loss: 0.4919 Acc: 0.7513\n",
            "Validation Loss: 0.4574 Acc: 0.7771\n",
            "Saved best model with Val Loss: 0.4574\n",
            "Epoch 15/20 - Train Loss: 0.4763 Acc: 0.7733\n",
            "Validation Loss: 0.4449 Acc: 0.7849\n",
            "Saved best model with Val Loss: 0.4449\n",
            "Epoch 16/20 - Train Loss: 0.4662 Acc: 0.7720\n",
            "Validation Loss: 0.4386 Acc: 0.8004\n",
            "Saved best model with Val Loss: 0.4386\n",
            "Epoch 17/20 - Train Loss: 0.4571 Acc: 0.7875\n",
            "Validation Loss: 0.4357 Acc: 0.7829\n",
            "Saved best model with Val Loss: 0.4357\n",
            "Epoch 18/20 - Train Loss: 0.4450 Acc: 0.7868\n",
            "Validation Loss: 0.4266 Acc: 0.8023\n",
            "Saved best model with Val Loss: 0.4266\n",
            "Epoch 19/20 - Train Loss: 0.4373 Acc: 0.7933\n",
            "Validation Loss: 0.4260 Acc: 0.8101\n",
            "Saved best model with Val Loss: 0.4260\n",
            "Epoch 20/20 - Train Loss: 0.4389 Acc: 0.7972\n",
            "Validation Loss: 0.4172 Acc: 0.8043\n",
            "Saved best model with Val Loss: 0.4172\n",
            "Training completed. Best model saved at: /content/drive/MyDrive/model/11110_best_model_ì´ˆê¸°í•™ìŠµ.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ëª¨ë¸ êµ¬ì¡°ë¥¼ ë‹¤ì‹œ ì •ì˜\n",
        "model = create_model()\n",
        "\n",
        "# 2. ì €ì¥ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
        "best_model_path = f\"/content/drive/MyDrive/model/{use_background}{use_agumentation}{use_dropout}{use_freezing}{use_l2}_best_model_ì´ˆê¸°í•™ìŠµ.pth\"\n",
        "state_dict = torch.load(best_model_path)\n",
        "\n",
        "# 3. ëª¨ë¸ì— ê°€ì¤‘ì¹˜ ì ìš©\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "# 4. ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
        "model.to(device)\n",
        "\n",
        "# 5. í‰ê°€ ëª¨ë“œ ì „í™˜ (ê¼­!)\n",
        "model.eval()\n",
        "\n",
        "# 6. í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
        "result = TestModel(model, testLoader)\n"
      ],
      "metadata": {
        "id": "lICt0ucFQJvP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b87c4ee-3871-4bc3-b20c-27636dfd5a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy  : 0.8101\n",
            "Test Loss      : 0.3916\n",
            "ROC-AUC        : 0.9080\n",
            "Precision      : 0.8135\n",
            "Recall         : 0.8109\n",
            "F1-macro       : 0.8098\n"
          ]
        }
      ]
    }
  ]
}